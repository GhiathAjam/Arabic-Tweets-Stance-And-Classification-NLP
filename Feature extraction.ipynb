{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words model  (BOW)\n",
    "# represent all the bags in a matrix of size (number of bags, number of words in the vocabulary) \n",
    "# each row is a bag and each column is a word in the vocabulary\n",
    "# the value in each cell is the number of times the word appears in the bag\n",
    "# the vocabulary is the set of all the words in the corpus\n",
    "# the corpus is the set of all the bags\n",
    "# the number of bags is the number of documents in the corpus\n",
    "# the number of words in the vocabulary is the number of unique words in the corpus\n",
    "\n",
    "\n",
    "# TF-IDF model\n",
    "# Word2Vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emojis:  True\n",
      "Lemmatizor:  camel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from preprocess import Preprocess \n",
    "preprocess = Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emada\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "t = pd.read_csv('./Dataset/train.csv')\n",
    "X = t['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do the preprocessing\n",
    "X = X.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ب\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer function takes sentences as input \n",
    "# convert it into matrix representation \n",
    "# where each cell will be filled by the frequency of each vocab\n",
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow_model.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1780</th>\n",
       "      <th>65</th>\n",
       "      <th>9kte81z1jk</th>\n",
       "      <th>co</th>\n",
       "      <th>https</th>\n",
       "      <th>lf</th>\n",
       "      <th>nnatra5bpb</th>\n",
       "      <th>qbustq1kpy</th>\n",
       "      <th>qqkffunwbn</th>\n",
       "      <th>user</th>\n",
       "      <th>...</th>\n",
       "      <th>يشتم</th>\n",
       "      <th>يطلع</th>\n",
       "      <th>يعنى</th>\n",
       "      <th>يعني</th>\n",
       "      <th>يقول</th>\n",
       "      <th>يكونو</th>\n",
       "      <th>يلا</th>\n",
       "      <th>يلي</th>\n",
       "      <th>يوصل</th>\n",
       "      <th>١٦</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1780  65  9kte81z1jk  co  https  lf  nnatra5bpb  qbustq1kpy  qqkffunwbn  \\\n",
       "0     0   2           0   1      1   0           0           0           1   \n",
       "1     0   0           0   0      0   4           0           0           0   \n",
       "2     0   0           0   0      0   2           0           0           0   \n",
       "3     0   0           0   1      1   0           0           1           0   \n",
       "4     0   0           0   0      0   1           0           0           0   \n",
       "5     0   0           0   1      1   1           1           0           0   \n",
       "6     0   0           0   0      0   0           0           0           0   \n",
       "7     0   0           0   0      0   2           0           0           0   \n",
       "8     1   0           1   1      1   4           0           0           0   \n",
       "9     0   0           0   0      0   1           0           0           0   \n",
       "\n",
       "   user  ...  يشتم  يطلع  يعنى  يعني  يقول  يكونو  يلا  يلي  يوصل  ١٦  \n",
       "0     0  ...     0     0     1     0     1      0    0    0     0   0  \n",
       "1     0  ...     0     0     0     1     0      0    1    0     0   0  \n",
       "2     0  ...     0     0     0     0     0      1    0    0     1   0  \n",
       "3     0  ...     0     0     0     0     0      0    0    0     0   0  \n",
       "4     1  ...     1     0     0     0     0      0    0    0     0   0  \n",
       "5     0  ...     0     0     0     0     0      0    0    0     0   0  \n",
       "6     0  ...     0     0     0     0     0      0    0    1     0   1  \n",
       "7     0  ...     0     0     0     0     0      0    0    0     0   0  \n",
       "8     1  ...     0     0     0     0     0      0    0    0     0   0  \n",
       "9     0  ...     0     1     0     0     0      0    0    0     0   0  \n",
       "\n",
       "[10 rows x 227 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the matrx into pandas dataframe \n",
    "# to set the column names as actual vocab words which are our features\n",
    "df_bow = pd.DataFrame(bow_model.toarray(), columns = vectorizer.get_feature_names())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1780', '65', '9kte81z1jk', 'co', 'https', 'lf', 'nnatra5bpb', 'qbustq1kpy', 'qqkffunwbn', 'user', 'ألفي', 'أميركا', 'أنقرة', 'أوكسفام', 'أول', 'إحدى', 'إسلامية', 'إنوا', 'اتابع', 'اد', 'اذا', 'اشترى', 'اصغر', 'اعلامية', 'ال', 'الآمن', 'الأجدر', 'الإنفوغراف', 'الابرة', 'الاخبار', 'التوزيع', 'التي', 'الثلاجة', 'الخطأ', 'الخليجية', 'الدواء', 'الدول', 'الدولة', 'الدين', 'السيرنجة', 'الشتاء', 'الصحة', 'الصحفي', 'الصيني', 'الضريبة', 'العادل', 'اللقاح', 'المارقة', 'المسؤولية', 'النظافة', 'الوحيد', 'الى', 'اليوم', 'امريكي', 'ان', 'انت', 'انه', 'انوا', 'اول', 'بالعاصمة', 'بالعالم', 'باي', 'بدعم', 'بدها', 'بدهم', 'بس', 'بعتقد', 'بعض', 'بفايزر', 'بفضل', 'بكرا', 'بكل', 'بمؤتمروا', 'بنذكر', 'بها', 'بوسطن', 'بولو', 'بيل', 'تاني', 'تجبر', 'تجيب', 'تحت', 'تدعي', 'تدفع', 'تركيا', 'تستحي', 'تصوير', 'تصير', 'تهكير', 'توقيفه', 'ثرواتهم', 'جاء', 'جرعة', 'حبيبي', 'حسابك', 'حضرتك', 'حفظت', 'دبي', 'دعبول', 'دعبول_دومه_مسحول', 'دولة', 'رح', 'رضت', 'سنة', 'شئت', 'شلنا', 'شي', 'صيفي', 'طريق', 'طلة', 'عاصي_الحلاني', 'عام', 'عامل', 'عاملين', 'عتويتر', 'عز', 'عشوا', 'عفوا', 'على', 'عليهم', 'عمر', 'عمره', 'عمرهم', 'عمل', 'عن', 'عندي', 'عوارض', 'غيتس', 'غير', 'فافعل', 'فخر', 'في', 'فيروس_اللامساواة', 'فيه', 'فيها', 'قائد', 'قادر', 'قريبا', 'قصة', 'قلق', 'قوجة', 'قولكن', 'كان', 'كل', 'كورونا', 'كورونافاك', 'كوفيد19', 'لأ', 'لأن', 'لا', 'لابس', 'لاخذ', 'لانه', 'لبنان', 'لبنان_ينتفض', 'لحد', 'لعد', 'لقاح', 'لقاح_الناس', 'لقاح_كورونا', 'للتلف', 'للحصول', 'لم', 'لما', 'لو', 'مؤامرة', 'مؤسسة', 'مؤهل', 'ما', 'مابدهم', 'ماذا', 'متزايد', 'متفوقين', 'مجالاتهم', 'مجبورين', 'محاربة_الفقر', 'محاربة_اللامساواة', 'مزايا', 'مستشفى', 'مش', 'مشكلة', 'مصاري', 'معوا', 'مفكرينها', 'مليونان', 'مليونيرا', 'من', 'منو', 'مين', 'نج', 'نفاق', 'هاي', 'هذا', 'هلأ', 'هم', 'هناك', 'هو', 'هي', 'وأخذ', 'وئام', 'واضح', 'والناس', 'واليوم', 'وتحديدا', 'وتطلب', 'وراح', 'وزير', 'وطرده', 'وقف', 'وما', 'وهاب', 'ويتسافه', 'ويلي', 'ياخذ', 'ياخذوا', 'يتلقى', 'يحتاج', 'يشتم', 'يطلع', 'يعنى', 'يعني', 'يقول', 'يكونو', 'يلا', 'يلي', 'يوصل', '١٦']\n"
     ]
    }
   ],
   "source": [
    "#show all features (unique words)\n",
    "print(vectorizer.get_feature_names())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec is trained to predict the nearest word belongs to the context\n",
    "# e.g. to tell if \"milk\" is a likely word given the \"The cat was drinking...\"\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=11771, vector_size=100, alpha=0.025>\n",
      "['<LF>', 'لَقاح', 'كَوَّر', '<LINK>', 'مِن']\n",
      "[ 0.14449823  0.8306925   0.225143    0.18542002  0.24939007 -1.0555822\n",
      "  1.0375941   1.4429084  -0.1662183  -1.0005652  -0.1835778  -0.40045434\n",
      " -0.18867132 -0.00219043 -0.09304217 -0.4387721  -0.28551638 -0.09178995\n",
      " -0.50763893 -1.5987117   0.75717545  0.4469516   1.1029341   0.28111878\n",
      " -0.31548724  0.0582037  -0.99022377  0.30520946 -0.33632177  0.377444\n",
      "  0.62215257 -1.3063688   0.93437743 -1.0268085   0.07434046  0.18212248\n",
      "  0.28211293 -0.00756995 -0.33030325 -0.4862275   0.08045409 -0.752534\n",
      " -0.80733836  0.43795994  0.4766529  -0.1585247  -0.522173    0.05857605\n",
      "  0.2881302   0.24929363  1.1353986  -1.0587391  -0.5062256  -1.3758435\n",
      " -0.66133344  0.36814743  0.67145413  0.11819714 -0.08818357 -0.10673913\n",
      " -0.8041448  -0.14759445  0.753933    0.10455376 -1.2721908   1.70026\n",
      "  0.9912442   0.7409311  -1.186192    1.2974757  -0.66350853  0.30371642\n",
      "  1.4455829   0.13995609  0.41288143 -0.41997617 -0.5719682  -0.16625437\n",
      " -0.82342154  0.22111408 -1.2663666   0.09942949 -0.65065974  0.8832765\n",
      " -0.03725377 -0.49968588  0.57262933 -0.11690887 -0.09575073 -0.43915033\n",
      "  1.125859   -0.6876352   0.61821795 -0.94233876  0.5920779   0.02647814\n",
      "  1.4331454  -0.4036343   0.12239719 -0.04630543]\n"
     ]
    }
   ],
   "source": [
    "# Create CBOW (Continuous Bag of Words) model \n",
    "model_cbow = Word2Vec(X, min_count = 1, vector_size = 100, window = 5) \n",
    "#applied on the preprocessed data X\n",
    "print(model_cbow)\n",
    "words_cbow = list(model_cbow.wv.index_to_key)\n",
    "print(words_cbow[0:5])\n",
    "\n",
    "# print the vector of a word\n",
    "print(model_cbow.wv['مِن'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=11771, vector_size=100, alpha=0.025>\n",
      "['<LF>', 'لَقاح', 'كَوَّر', '<LINK>', 'مِن']\n",
      "[-0.1553118   0.06690425  0.00581679  0.25754067  0.4526745  -0.8358616\n",
      "  0.4802734   0.431172   -0.19658463 -0.22368757 -0.43428275 -0.3381759\n",
      " -0.06288696 -0.04593816  0.14483598 -0.21102586 -0.08131736 -0.18813345\n",
      " -0.26784262 -0.631896    0.23929377  0.00789269  0.5492359   0.1738618\n",
      " -0.03279758  0.2035647  -0.14876339  0.12412742 -0.28709882 -0.0031332\n",
      " -0.02334978 -0.45734087  0.29842266 -0.550115    0.18394285  0.08244283\n",
      "  0.0660438  -0.08217748  0.14413536 -0.00605095  0.3111171  -0.73374647\n",
      " -0.35174814  0.33512443  0.34303313 -0.10791266 -0.01600224 -0.07477792\n",
      "  0.08092833 -0.00860715  0.31950772 -0.49093226  0.16607873 -0.42681178\n",
      "  0.03270544 -0.01564509  0.21856004 -0.14412296 -0.15127444  0.01256174\n",
      " -0.08251856 -0.20838176  0.06021815  0.18737827 -0.17037232  0.27663806\n",
      "  0.32320967  0.48157308 -0.4800596   0.43304908 -0.02736206  0.09811998\n",
      "  0.61586475 -0.0380644   0.23198034  0.07187128 -0.4532332   0.00452691\n",
      "  0.08700843 -0.19570997 -0.4759576   0.10963948 -0.08064494  0.07079541\n",
      "  0.12770656 -0.13276277  0.15893057  0.03563239 -0.2125585  -0.07940912\n",
      "  0.22838573 -0.40250903  0.11804169 -0.21263592  0.1826044   0.13419388\n",
      "  0.49619132 -0.18940319 -0.01223418  0.15271369]\n"
     ]
    }
   ],
   "source": [
    "model_sg = Word2Vec(X, min_count = 1, vector_size = 100, window = 5, sg=1) \n",
    "#applied on the preprocessed data X\n",
    "print(model_sg)\n",
    "words_cbow = list(model_sg.wv.index_to_key)\n",
    "print(words_cbow[0:5])\n",
    "\n",
    "# print the vector of a word\n",
    "print(model_sg.wv['مِن'])\n",
    "\n",
    "# model_sg.wv['word']: has the vector of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "54d93ce000fb5f8fcca2dab3e75c99c50bb371be07ecadf3a0d8d467af599caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
