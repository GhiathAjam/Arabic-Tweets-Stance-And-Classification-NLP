{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y024z5AnlTLz",
        "outputId": "f262a722-c25e-4dea-8d3f-50ba9c4e5eab"
      },
      "outputs": [],
      "source": [
        "# # From paper\n",
        "# !pip install farasapy==0.0.14\n",
        "# !pip install transformers==4.12.2\n",
        "# !git clone https://github.com/aub-mind/arabert\n",
        "# !pip install pyarabic==0.6.14\n",
        "# !pip install sentencepiece==0.1.96\n",
        "# !pip install emoji==1.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr84ozGinCFh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-WYy5ikAs7l3"
      },
      "outputs": [],
      "source": [
        "tx=\"text\"\n",
        "st=\"stance\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6oL3qkXmOgJ",
        "outputId": "d9d8ea0b-9ff8-470d-cea3-bb0bb4d94158"
      },
      "outputs": [],
      "source": [
        "# model from hugging face\n",
        "# trained on twitter data\n",
        "model_name = 'aubmindlab/bert-base-arabertv02-twitter'\n",
        "\n",
        "train = pd.read_csv(\"./Dataset/train.csv\")\n",
        "train = train[[tx,st]]\n",
        "\n",
        "print(train[st].value_counts())\n",
        "map = {\n",
        "    1: 'POS',\n",
        "    0: 'NEU',\n",
        "    -1: 'NEG',\n",
        "}\n",
        "train[st] = train[st].apply(lambda x: map[x])\n",
        "\n",
        "test = pd.read_csv('./Dataset/dev.csv')\n",
        "test = test[[tx,st]]\n",
        "test[st] = test[st].apply(lambda x: map[x])\n",
        "\n",
        "print(test.head())\n",
        "\n",
        "label_list = test[st].unique()\n",
        "print(label_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcwdslw7v0Q8"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhcYKB663eoz"
      },
      "source": [
        "Start the training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HUn2RB6Bvrxj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, f1_score, precision_score,\n",
        "                             recall_score)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertTokenizer, Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.data.processors.utils import InputFeatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icuhwx3S4NLM"
      },
      "source": [
        "Create and apply preprocessing using the AraBERT processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt_lGy85zuca"
      },
      "outputs": [],
      "source": [
        "arabic_prep = ArabertPreprocessor(model_name)\n",
        "\n",
        "# apply preprocessing to the dataset\n",
        "train[tx] = train[tx].apply(lambda x: arabic_prep.preprocess(x))\n",
        "test[tx] = test[tx].apply(lambda x: arabic_prep.preprocess(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-tHPrqeEqHm",
        "outputId": "08a0b40d-e8b7-497d-b903-51eb21f41eae"
      },
      "outputs": [],
      "source": [
        "# check\n",
        "print(train[tx][0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH2yldN-4vcX"
      },
      "source": [
        "Now we need to check the tokenized sentence length to decide on the maximum sentence length value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "IOVdVmfEguAT",
        "outputId": "016140c7-9df3-4b32-e2c7-14a6deb6d041"
      },
      "outputs": [],
      "source": [
        "tok = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "pP5ziUabgpeb",
        "outputId": "cc39154e-03bf-456e-f607-b6f738fc9c5b"
      },
      "outputs": [],
      "source": [
        "print(\"Training Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in train[tx].to_list()],bins=range(0,128,2))\n",
        "plt.show()\n",
        "\n",
        "print(\"Testing Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in test[tx].to_list()],bins=range(0,128,2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLhNqO2w5DIn",
        "outputId": "00a4a12f-b8b0-4523-e0cb-1f78a48fc22e"
      },
      "outputs": [],
      "source": [
        "max_len = 90\n",
        "\n",
        "print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in train[tx].to_list()]))\n",
        "\n",
        "print(\"Truncated testing sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in test[tx].to_list()]))\n",
        "\n",
        "dic = {}\n",
        "x1 = train\n",
        "for i in range(len(x1[tx])):\n",
        "  if len(tok.tokenize(x1[tx][i])) > max_len:\n",
        "    dic[x1[st][i]] = dic.get(x1[st][i], 0) +1\n",
        "print(dic, ':(')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFHzbq6p8P2C"
      },
      "source": [
        "Create a function that return a pretrained model ready to do classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt7l0IxjbmNu"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WCYBfiB8hIb"
      },
      "source": [
        "Define whatever metric you want here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYU6G4vWc5nz"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  #print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  #macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  #macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {       \n",
        "      'macro_f1' : macro_f1,\n",
        "      'accuracy': acc\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEznOOD4COn7"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic=True\n",
        "  torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTmvFEs41WkV"
      },
      "source": [
        "# Iterations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hym-1aiJ8zS8"
      },
      "source": [
        "Ref:\n",
        "https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BplVarm6h6qj"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments( \n",
        "    output_dir= \"./train\",    \n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 1e-5,\n",
        "    fp16 = False, # enable this when using V100 or T4 GPU\n",
        "    per_device_train_batch_size = 16, # up to 64 on 16GB with max len of 128\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2, # use this to scale batch size without needing more memory\n",
        "    num_train_epochs= 5,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 1\n",
        "  )\n",
        "\n",
        "set_seed(training_args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVODSK3D89OZ"
      },
      "source": [
        "Create the trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro5BW5ak4uc1",
        "outputId": "6b47177e-c9c4-4c8e-daa2-35cf3192f63f"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train,\n",
        "    eval_dataset=test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "mxqoZsFWSFso",
        "outputId": "544685b5-7a7e-44f9-c262-cc7efd9e3010"
      },
      "outputs": [],
      "source": [
        "#start the training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZJE_H0j-ldm"
      },
      "source": [
        "### Saving The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pru84em-lMR"
      },
      "outputs": [],
      "source": [
        "inv_label_map = inv_label_map = { v:k for k, v in label_map.items()}\n",
        "print(inv_label_map)\n",
        "trainer.model.config.label2id = label_map\n",
        "trainer.model.config.id2label = inv_label_map\n",
        "fold = \"arabert02_official_batch32_somesampling_658972f1\"\n",
        "trainer.save_model(fold)\n",
        "train_dataset.tokenizer.save_pretrained(fold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Saving to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckb8jYZu_pCu"
      },
      "outputs": [],
      "source": [
        "# copy the model to drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !cp -r arabert02_official_original_652f1 /content/drive/MyDrive\n",
        "# !ls '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaDLMebgF8EE"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFqMbH5uF-TR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from transformers import pipeline\n",
        "# initialize pipline\n",
        "drive.mount('./drive')\n",
        "model_name = \"/content/drive/MyDrive/NLP/arabert02_official_original_652f1\"\n",
        "hf_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
        "pipe = pipeline(\"sentiment-analysis\", model=model_name, device=0, return_all_scores=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dev set, make sure model is saved and loaded correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx4k9zqkF7Wb",
        "outputId": "f837cae4-12c7-43c8-bce3-4fa0c1c264b8"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('./dev.csv')\n",
        "test = test[[tx,st]]\n",
        "map = {\n",
        "    1: 'POS',\n",
        "    0: 'NEU',\n",
        "    -1: 'NEG',\n",
        "}\n",
        "test[st] = test[st].apply(lambda x: map[x])\n",
        "# label_list = ['NEG', 'NEU', 'POS']\n",
        "label_list = test[st].unique()\n",
        "print(test.head())\n",
        "print(test[st].value_counts())\n",
        "print(label_list)\n",
        "\n",
        "arabic_prep = ArabertPreprocessor(hf_name)\n",
        "tok = AutoTokenizer.from_pretrained(hf_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MMAY4yMui-n8",
        "outputId": "a3c6d39d-742e-4514-c228-bad680260723"
      },
      "outputs": [],
      "source": [
        "# try pipe\n",
        "# (pipe('sad')[0]['label'])\n",
        "\n",
        "def predict(text):\n",
        "  return pipe(text)[0]['label']\n",
        "\n",
        "predict('sad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40tUdGdxghqI",
        "outputId": "bf2deeba-b7f8-47a7-ed52-0e277cdd6a6e"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "X = test\n",
        "labels = X['stance']\n",
        "pred = []\n",
        "\n",
        "for i, txi in enumerate(X.text):\n",
        "    pred += [predict(txi)]\n",
        "\n",
        "print(metrics.classification_report(labels, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0anFYrGmWBG",
        "outputId": "62aa5c26-c292-4b67-a999-d04bb5af759b"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('./test.csv')\n",
        "map = {\n",
        "    1: 'POS',\n",
        "    0: 'NEU',\n",
        "    -1: 'NEG',\n",
        "}\n",
        "label_list = ['NEG', 'NEU', 'POS']\n",
        "print(test.head())\n",
        "print(label_list)\n",
        "\n",
        "arabic_prep = ArabertPreprocessor(hf_name)\n",
        "tok = AutoTokenizer.from_pretrained(hf_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD3ZSLr0lSg3",
        "outputId": "74c91859-6cee-4fea-b487-340c5a27aef7"
      },
      "outputs": [],
      "source": [
        "# from sklearn import metrics\n",
        "\n",
        "X = test\n",
        "# labels = X['stance']\n",
        "pred = []\n",
        "\n",
        "mp = {\n",
        "    \"POS\": 1,\n",
        "    \"NEU\": 0,\n",
        "    \"NEG\": -1\n",
        "}\n",
        "\n",
        "for i, txi in enumerate(X.text):\n",
        "    # pred.append((X.id[i], mp[pipe(arabic_prep.preprocess(txi))[0]['label']]))\n",
        "    pred.append((X.id[i], mp[predict(txi)]))\n",
        "\n",
        "print(pred[:15])\n",
        "# print(pred.value_counts())\n",
        "# print(metrics.classification_report(labels, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### CSV output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6aDZyheo0Ca",
        "outputId": "481d1889-1511-4ab3-d291-3cb7b5ae8bfa"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('./out/test_stance_NO_preprocess.csv', \"w\",encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(('id','stance'))\n",
        "    for row in pred:\n",
        "        writer.writerow(row)\n",
        "\n",
        "dd = pd.read_csv('./out/test_stance_NO_preprocess.csv')\n",
        "print(dd.info())\n",
        "print(dd.head())\n",
        "\n",
        "print(dd.stance.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecQR0_tGDQ0",
        "outputId": "5ba49aaf-48b8-4a68-e808-6abef28155a4"
      },
      "outputs": [],
      "source": [
        "text = \"بحمد الله تم أخذ الجرعة الأولى من #لقاح_كورونا https://t.co/cWiFmKfKhV\"\n",
        "print(pipe(text))\n",
        "\n",
        "p = arabic_prep.preprocess(text)\n",
        "print(p)\n",
        "\n",
        "print(pipe(p))\n",
        "\n",
        "tk = tok.tokenize(p)\n",
        "print(tk)\n",
        "\n",
        "#\n",
        "pipe(tk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4LvAHb1gsrA",
        "outputId": "2b56dbca-04d1-4084-d077-cdca1e79b085"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfNwCtgvgql0"
      },
      "outputs": [],
      "source": [
        "pipe([\"كو\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPJ46HU3GVeS"
      },
      "outputs": [],
      "source": [
        "# !rm -rf train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIL2va_mvPzw"
      },
      "outputs": [],
      "source": [
        "iasdhkjlafsd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcMplCCFUPBP"
      },
      "source": [
        "# K-fold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr3tPLSB_vSN"
      },
      "source": [
        "This section is bit more advanced.\n",
        "\n",
        "We will divide the training set into K-folds and train model with cross-validation to check for the best hyper-parameters before check the performance on the test set.\n",
        "\n",
        "Alternatively, you can combine the training and testing set if you are participating in a competition, then ensemble the output models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vpem-JlUS8W"
      },
      "outputs": [],
      "source": [
        "# do kfold on the training. Check the perfomance on the test set\n",
        "kfold_dataset = selected_dataset.train\n",
        "# do kfold on all the dataset. Here we will not have any dataset to checl final performance on (this is used mainly in competitions)\n",
        "# kfold_dataset = pd.concat([selected_dataset.train,selected_dataset.test])\n",
        "kfold_dataset.reset_index(inplace=True,drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhpJcw3YUuh9"
      },
      "outputs": [],
      "source": [
        "# this is used later\n",
        "inv_label_map = { v:k for k, v in label_map.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DGjYvn7BBUg"
      },
      "source": [
        "Defing the number of Stratified kfold splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOmi63psUS8X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kf = StratifiedKFold(\n",
        "    n_splits=5,\n",
        "    shuffle=True,\n",
        "    random_state=123\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF2JYbkSC8KA"
      },
      "source": [
        "Train using cross validation and save the best model at each fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHUsDFTeUyKr"
      },
      "outputs": [],
      "source": [
        "all_results = []\n",
        "fold_best_f1 = 0\n",
        "best_fold = None\n",
        "for fold_num , (train, dev) in enumerate(kf.split(kfold_dataset,kfold_dataset['label'])):\n",
        "  print(\"**************************Starting Fold Num: \", fold_num,\" **************************\")\n",
        "  \n",
        "  train_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][train]),\n",
        "                              list(kfold_dataset[LABEL_COLUMN][train]),\n",
        "                              model_name,\n",
        "                              max_len,\n",
        "                              label_map)\n",
        "  \n",
        "  val_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][dev]),\n",
        "                              list(kfold_dataset[LABEL_COLUMN][dev]),\n",
        "                              model_name,\n",
        "                              max_len,\n",
        "                              label_map)\n",
        "  \n",
        "  training_args = TrainingArguments( \n",
        "    output_dir= f\"./train_{fold_num}\",    \n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False,\n",
        "    per_device_train_batch_size = 64,\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 123\n",
        "  )\n",
        "\n",
        "  set_seed(training_args.seed)\n",
        "\n",
        "  trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "  )\n",
        "  trainer.model.config.label2id = label_map\n",
        "  trainer.model.config.id2label = inv_label_map\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  results = trainer.evaluate()\n",
        "  all_results.append(results)\n",
        "  print(results)\n",
        "\n",
        "  trainer.save_model(f\"./train_{fold_num}/best_model\")\n",
        "  val_dataset.tokenizer.save_pretrained(f\"./train_{fold_num}/best_model\")\n",
        "\n",
        "  # delete the rest of the checkpoints\n",
        "  !rm -rf f\"./train_{fold_num}/checkpoint-*\" \n",
        "  \n",
        "  if results['eval_macro_f1'] > fold_best_f1:\n",
        "    print('**************************New Best Model Found!**************************')\n",
        "    fold_best_f1 = results['eval_macro_f1']\n",
        "    best_fold = fold_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTouNECWprWI"
      },
      "outputs": [],
      "source": [
        "all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yBbzQcCqb1m"
      },
      "outputs": [],
      "source": [
        "from statistics import mean\n",
        "mean([x['eval_macro_f1'] for x in all_results])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX7sa1AlGpba"
      },
      "source": [
        "After checking for the best hyper parameters you should use the regular training section and retrain the model with the parameters that you had here.\n",
        "\n",
        "Or Ensemble the models together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvaIKiGcEl3K"
      },
      "source": [
        "## Ensemble all the cross validation models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRvWyT6iY1gt"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import more_itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbsAt4d3veZH"
      },
      "outputs": [],
      "source": [
        "inv_label_map = { v:k for k, v in label_map.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9X02dm4LDFc"
      },
      "source": [
        "Load some file which has text that we need to run inference on. \n",
        "I will use the test set for that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa5QeMo0p6-G"
      },
      "outputs": [],
      "source": [
        "# pred_df = prediction['Text']\n",
        "# pred_df = pred_df.apply(lambda x:   arabic_prep.preprocess(x))\n",
        "\n",
        "pred_df = selected_dataset.test[DATA_COLUMN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wyQDPxBVbfB"
      },
      "outputs": [],
      "source": [
        "cross_val_df = pd.DataFrame([])\n",
        "for i in range(0,5):\n",
        "  pipe = pipeline(\"sentiment-analysis\", model=f\"train_{i}/best_model\", device=0, return_all_scores =True, max_length=max_len, truncation=True)\n",
        "  preds = []\n",
        "  for s in tqdm(more_itertools.chunked(list(pred_df), 32)): # batching for faster inference\n",
        "    preds.extend(pipe(s))\n",
        "  cross_val_df[f'model_{i}'] = preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj6cF1Tzsk73"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "final_labels = []\n",
        "final_scores = []\n",
        "for id, row in cross_val_df.iterrows():\n",
        "  total_score = defaultdict(lambda: 0)  \n",
        "  for pred in row:\n",
        "    for cls in pred:\n",
        "      total_score[cls['label']] += cls['score']\n",
        "\n",
        "  avg_score = { k: v/ 5 for k, v in total_score.items()}\n",
        "\n",
        "  final_labels.append(max(avg_score, key=avg_score.get))\n",
        "  final_scores.append(avg_score[max(avg_score, key=avg_score.get)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZzeOZ2HvhtT"
      },
      "outputs": [],
      "source": [
        "cross_val_df['preds'] = final_labels \n",
        "cross_val_df['sentiment_score'] = final_scores "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKEgO6XYcnal"
      },
      "outputs": [],
      "source": [
        "cross_val_df['preds'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt1dbA9rRx8f"
      },
      "outputs": [],
      "source": [
        "print(classification_report(selected_dataset.test[LABEL_COLUMN],cross_val_df['preds']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NcMplCCFUPBP"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
