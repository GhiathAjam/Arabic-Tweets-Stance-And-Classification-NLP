{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics \n",
    "\n",
    "# Can use this library to reload a specific module if the notebook can't see changes in the imported module\n",
    "import importlib\n",
    "from torch import nn\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import stance_classes, category_classes\n",
    "import random as rnd\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('./Dataset/classification_train_sample1.csv')\n",
    "d = pd.read_csv('./Dataset/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_beforeTokenization = t['text']\n",
    "yc = t['category']\n",
    "yc_val = yc.replace(category_classes)\n",
    "# we need values to be from 0 to 9 instead of from 1 to 10\n",
    "yc_val -=1\n",
    "\n",
    "X_beforeTokenization_dev = d['text']\n",
    "yc_dev = d['category']\n",
    "yc_val_dev = yc_dev.replace(category_classes)\n",
    "yc_val_dev -=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
    "X = X_beforeTokenization.apply(arabert_prep.preprocess)\n",
    "X_val = X_beforeTokenization_dev.apply(arabert_prep.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(x):\n",
    "        input_ids = []\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        for i in range(len(x)):\n",
    "        # tokenize each sentence using bert's tokenizer\n",
    "        # the tokenizer returns a batch encoding, which is derived from a dictionary\n",
    "        # this dictionary holds the various inputs needed by the model of such tokenizer.\n",
    "                encoded_sentence = tokenizer.encode_plus(\n",
    "                        text=x[i],                      # Preprocess sentence\n",
    "                        add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "                        max_length=64,                  # Max length to truncate/pad # tuned?\n",
    "                                                        # The model is trained on a sequence length of 64, using max length beyond 64 might result in degraded performance\n",
    "                        padding='max_length',           # Pad sentence to max length\n",
    "                        return_attention_mask=True,     # Return attention mask\n",
    "                        truncation = True)\n",
    "                input_ids.append(encoded_sentence.get('input_ids'))\n",
    "        input_ids = np.array(input_ids)\n",
    "        return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refrence token to number\n",
    "input_ids_train = tokenizing(X)\n",
    "input_ids_test = tokenizing(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all words in the dataset \n",
    "lst = [word for x in input_ids_train for word in x]\n",
    "\n",
    "# unique words\n",
    "vocab = list(set(lst))\n",
    "vocab_lengthing = len(vocab)\n",
    "\n",
    "# map ids of train/test to numbers from 0 to vocab_lengthing in order to be consistent with embedding matrix\n",
    "for i in range(len(vocab)):\n",
    "    input_ids_train[input_ids_train==vocab[i]]=i\n",
    "    input_ids_test[input_ids_test==vocab[i]]=i\n",
    "\n",
    "# map unknowns (not found in train) in test data to a token id value -> vocab_lengthing\n",
    "input_ids_test[input_ids_test > vocab_lengthing] = vocab_lengthing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, y):\n",
    "    \n",
    "    self.tensor_x = torch.tensor(x)\n",
    "    self.tensor_y = torch.tensor(y)\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.tensor_x)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.tensor_x[idx], self.tensor_y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = LSTMDataset(input_ids_train, yc_val)\n",
    "dataset_test = LSTMDataset(input_ids_test, yc_val_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self, vocab_size=35181, embedding_dim=300, hidden_size=50, n_classes=len(list(category_classes.keys()))):\n",
    "\n",
    "    super(LSTM, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.lstm = nn.LSTM(embedding_dim, hidden_size,num_layers = 3, batch_first=True)\n",
    "    self.linear = nn.Linear(hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, sentences):\n",
    "\n",
    "    final_output = None\n",
    "    sentences = self.embedding(sentences)\n",
    "    sentences, _ = self.lstm(sentences)\n",
    "    sentences = torch.mean(sentences, 1)\n",
    "    sentences = self.linear(sentences)\n",
    "    final_output = sentences\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all words in the dataset \n",
    "lst = [word for x in input_ids_train for word in x]\n",
    "\n",
    "# unique words\n",
    "vocab = set(lst)\n",
    "model = LSTM(vocab_size = len(vocab)+2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_lstm(model, train_dataset, val_dataset, criterion, optimizer, classes_names, n_classes=3, batch_size=256, epochs=30):\n",
    "\n",
    "  # dataloader divides dataset into batches \n",
    "  train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
    "  \n",
    "  # create a dictionary that holds both train and validation\n",
    "  dataloader = {\n",
    "      \"train\": train_dataloader,\n",
    "      \"val\": val_dataloader}\n",
    "\n",
    "  # GPU configuration\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  if use_cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "  for epoch_num in range(epochs):\n",
    "\n",
    "      for phase in ['train', 'val']:\n",
    "          if phase == 'train':  # put the model in training mode\n",
    "              model.train()\n",
    "          else:\n",
    "              # put the model in validation mode, in order not to update parameters in dropout.\n",
    "              model.eval()\n",
    "\n",
    "          # keep track of training and validation loss    \n",
    "          total_acc_train = 0\n",
    "          total_loss_train = 0\n",
    "          train_labels = []\n",
    "          train_preds = []\n",
    "        \n",
    "          for train_input, train_label in dataloader[phase]:\n",
    "              # train_input: sentences\n",
    "              # move data to the device\n",
    "              train_label = train_label.to(device)\n",
    "              train_input = train_input.to(device)\n",
    "\n",
    "              # do the forward pass\n",
    "              output = model(train_input)\n",
    "              \n",
    "              # The docs of the loss function expects:\n",
    "              # input of shape: (batch_size, n_classes)\n",
    "              # target of shape: (btach_size)\n",
    "              # loss calculation\n",
    "              batch_loss = criterion(output, train_label)\n",
    "\n",
    "              # append the batch loss to the total_loss_train\n",
    "              total_loss_train += batch_loss\n",
    "              \n",
    "              # calculate the batch accuracy (just add the number of correct predictions)\n",
    "              # torch.Tensor.item(): Returns the value of this tensor as a standard Python number. This only works for tensors with one element.\n",
    "              train_pred = torch.argmax(output, dim=-1)\n",
    "\n",
    "              num_correct_predictions = (train_pred == train_label).sum().item()\n",
    "              acc = num_correct_predictions\n",
    "              total_acc_train += acc\n",
    "\n",
    "              if phase == 'train':\n",
    "                  # zero your gradients\n",
    "                  optimizer.zero_grad()\n",
    "                  # do the backward pass\n",
    "                  batch_loss.backward()\n",
    "                  # update the weights with your optimizer\n",
    "                  optimizer.step()\n",
    "              \n",
    "              # move data to cpu then numpy so you can make use of sklearn metric functions\n",
    "              train_labels += list(train_label.to('cpu').detach().numpy())\n",
    "              train_preds += list(train_pred.to('cpu').detach().numpy())\n",
    "              \n",
    "          # calculate epoch's loss\n",
    "          # len(train_dataset) will call the __len__ of the LSTMDataset\n",
    "          # will return the number of sentences in the dataset\n",
    "          if phase == 'train':\n",
    "            sentences_count = len(train_dataset)\n",
    "          else:\n",
    "            sentences_count = len(val_dataset)\n",
    "\n",
    "          # Measuring performance\n",
    "          # calculate epoch's accuracy and loss\n",
    "          epoch_loss = total_loss_train / sentences_count\n",
    "          epoch_acc = total_acc_train / sentences_count\n",
    "          report = metrics.classification_report(train_labels, train_preds, target_names=classes_names, digits=4, output_dict=True)\n",
    "          \n",
    "          print(f'Epochs: {epoch_num + 1} | {phase} Loss: {epoch_loss} | {phase} Accuracy: {epoch_acc} | {phase} macro avg persision: {report[\"macro avg\"]}\\n')\n",
    "          \n",
    "          if epoch_num % 5==0:\n",
    "            # calculate the classification report each 5 epochs\n",
    "            report = metrics.classification_report(train_labels, train_preds, target_names=classes_names, digits=4)\n",
    "            print(f'Classification Report: {report}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the criterion cross entropy loss, calculate error\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# create the optimizer (Adam), updates the weights\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | train Loss: 0.006494984962046146 | train Accuracy: 0.40940265486725663 | train macro avg persision: {'precision': 0.3937346956479821, 'recall': 0.40940265486725663, 'f1-score': 0.3918878446332858, 'support': 36160}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.2072    0.0606    0.0937      3616\n",
      "   celebrity     0.4814    0.5998    0.5341      3616\n",
      "        plan     0.2589    0.4311    0.3235      3616\n",
      "    requests     0.4873    0.5354    0.5102      3616\n",
      "      rumors     0.5015    0.4967    0.4991      3616\n",
      "      advice     0.5045    0.3844    0.4364      3616\n",
      "restrictions     0.6163    0.7270    0.6671      3616\n",
      "    personal     0.2608    0.1822    0.2146      3616\n",
      "   unrelated     0.3922    0.4923    0.4366      3616\n",
      "      others     0.2273    0.1845    0.2036      3616\n",
      "\n",
      "    accuracy                         0.4094     36160\n",
      "   macro avg     0.3937    0.4094    0.3919     36160\n",
      "weighted avg     0.3937    0.4094    0.3919     36160\n",
      "\n",
      "\n",
      "Epochs: 1 | val Loss: 0.008014499209821224 | val Accuracy: 0.212 | val macro avg persision: {'precision': 0.19912410715199594, 'recall': 0.24341507519963362, 'f1-score': 0.17261340063991362, 'support': 1000}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.5507    0.0697    0.1238       545\n",
      "   celebrity     0.6354    0.7931    0.7055       145\n",
      "        plan     0.0798    0.1585    0.1061        82\n",
      "    requests     0.1667    0.1500    0.1579        20\n",
      "      rumors     0.0411    0.2000    0.0682        15\n",
      "      advice     0.0136    0.4000    0.0263        10\n",
      "restrictions     0.0000    0.0000    0.0000         2\n",
      "    personal     0.2299    0.1562    0.1860       128\n",
      "   unrelated     0.2333    0.3889    0.2917        36\n",
      "      others     0.0408    0.1176    0.0606        17\n",
      "\n",
      "    accuracy                         0.2120      1000\n",
      "   macro avg     0.1991    0.2434    0.1726      1000\n",
      "weighted avg     0.4414    0.2120    0.2182      1000\n",
      "\n",
      "\n",
      "Epochs: 2 | train Loss: 0.0024848796892911196 | train Accuracy: 0.8061117256637168 | train macro avg persision: {'precision': 0.7941510238185183, 'recall': 0.8061117256637168, 'f1-score': 0.7918660327120103, 'support': 36160}\n",
      "\n",
      "Epochs: 2 | val Loss: 0.00634493213146925 | val Accuracy: 0.394 | val macro avg persision: {'precision': 0.25836199818547534, 'recall': 0.27537341656572834, 'f1-score': 0.24331894115340735, 'support': 1000}\n",
      "\n",
      "Epochs: 3 | train Loss: 0.001598051399923861 | train Accuracy: 0.871570796460177 | train macro avg persision: {'precision': 0.8673287147744091, 'recall': 0.8715707964601769, 'f1-score': 0.8656752203465397, 'support': 36160}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | val Loss: 0.006853986997157335 | val Accuracy: 0.382 | val macro avg persision: {'precision': 0.250784252300955, 'recall': 0.274414400710857, 'f1-score': 0.23337982267723953, 'support': 1000}\n",
      "\n",
      "Epochs: 4 | train Loss: 0.001135127735324204 | train Accuracy: 0.9142699115044248 | train macro avg persision: {'precision': 0.912832880078237, 'recall': 0.9142699115044248, 'f1-score': 0.9111479592796522, 'support': 36160}\n",
      "\n",
      "Epochs: 4 | val Loss: 0.006690312176942825 | val Accuracy: 0.502 | val macro avg persision: {'precision': 0.33857363839220367, 'recall': 0.3366458972896854, 'f1-score': 0.32625321008361274, 'support': 1000}\n",
      "\n",
      "Epochs: 5 | train Loss: 0.0008016804931685328 | train Accuracy: 0.9430862831858408 | train macro avg persision: {'precision': 0.9428647883789946, 'recall': 0.9430862831858405, 'f1-score': 0.9419181272132766, 'support': 36160}\n",
      "\n",
      "Epochs: 5 | val Loss: 0.006829148158431053 | val Accuracy: 0.522 | val macro avg persision: {'precision': 0.3083513789089788, 'recall': 0.32753446130325187, 'f1-score': 0.308737257720319, 'support': 1000}\n",
      "\n",
      "Epochs: 6 | train Loss: 0.0006404415471479297 | train Accuracy: 0.9553097345132744 | train macro avg persision: {'precision': 0.9553371231337184, 'recall': 0.9553097345132745, 'f1-score': 0.9546143526990493, 'support': 36160}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.8868    0.7716    0.8252      3616\n",
      "   celebrity     0.9707    0.9726    0.9717      3616\n",
      "        plan     0.8763    0.9577    0.9152      3616\n",
      "    requests     0.9297    0.9945    0.9610      3616\n",
      "      rumors     0.9964    0.9892    0.9928      3616\n",
      "      advice     0.9939    0.9992    0.9966      3616\n",
      "restrictions     0.9994    1.0000    0.9997      3616\n",
      "    personal     0.9478    0.9239    0.9357      3616\n",
      "   unrelated     0.9799    0.9726    0.9763      3616\n",
      "      others     0.9723    0.9718    0.9721      3616\n",
      "\n",
      "    accuracy                         0.9553     36160\n",
      "   macro avg     0.9553    0.9553    0.9546     36160\n",
      "weighted avg     0.9553    0.9553    0.9546     36160\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | val Loss: 0.006842697970569134 | val Accuracy: 0.563 | val macro avg persision: {'precision': 0.2880470782239698, 'recall': 0.27380071404457157, 'f1-score': 0.27537916206453666, 'support': 1000}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.6755    0.6532    0.6642       545\n",
      "   celebrity     0.7959    0.8069    0.8014       145\n",
      "        plan     0.1961    0.2439    0.2174        82\n",
      "    requests     0.2000    0.1000    0.1333        20\n",
      "      rumors     0.0000    0.0000    0.0000        15\n",
      "      advice     0.2500    0.1000    0.1429        10\n",
      "restrictions     0.0000    0.0000    0.0000         2\n",
      "    personal     0.3759    0.4141    0.3941       128\n",
      "   unrelated     0.3514    0.3611    0.3562        36\n",
      "      others     0.0357    0.0588    0.0444        17\n",
      "\n",
      "    accuracy                         0.5630      1000\n",
      "   macro avg     0.2880    0.2738    0.2754      1000\n",
      "weighted avg     0.5675    0.5630    0.5641      1000\n",
      "\n",
      "\n",
      "Epochs: 7 | train Loss: 0.0005952348583377898 | train Accuracy: 0.9586006637168142 | train macro avg persision: {'precision': 0.9584687665096341, 'recall': 0.958600663716814, 'f1-score': 0.9582360936313741, 'support': 36160}\n",
      "\n",
      "Epochs: 7 | val Loss: 0.007624393329024315 | val Accuracy: 0.532 | val macro avg persision: {'precision': 0.29129178705427206, 'recall': 0.27078609757534855, 'f1-score': 0.2707355027376237, 'support': 1000}\n",
      "\n",
      "Epochs: 8 | train Loss: 0.00045749504351988435 | train Accuracy: 0.9688329646017699 | train macro avg persision: {'precision': 0.9688563503786938, 'recall': 0.9688329646017699, 'f1-score': 0.968570284299733, 'support': 36160}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | val Loss: 0.007557963021099567 | val Accuracy: 0.544 | val macro avg persision: {'precision': 0.2679782394525751, 'recall': 0.2523651673641064, 'f1-score': 0.25605826339970217, 'support': 1000}\n",
      "\n",
      "Epochs: 9 | train Loss: 0.0003873550449497998 | train Accuracy: 0.9749446902654867 | train macro avg persision: {'precision': 0.9750106246381852, 'recall': 0.9749446902654867, 'f1-score': 0.9747940754716635, 'support': 36160}\n",
      "\n",
      "Epochs: 9 | val Loss: 0.0076604881323874 | val Accuracy: 0.564 | val macro avg persision: {'precision': 0.27878885394265784, 'recall': 0.2619369953307671, 'f1-score': 0.26523450441040974, 'support': 1000}\n",
      "\n",
      "Epochs: 10 | train Loss: 0.00032908120192587376 | train Accuracy: 0.9785674778761062 | train macro avg persision: {'precision': 0.9786443179793766, 'recall': 0.9785674778761061, 'f1-score': 0.9784459442527036, 'support': 36160}\n",
      "\n",
      "Epochs: 10 | val Loss: 0.007947646081447601 | val Accuracy: 0.576 | val macro avg persision: {'precision': 0.2969678950885137, 'recall': 0.2533719590962519, 'f1-score': 0.2600913759977584, 'support': 1000}\n",
      "\n",
      "Epochs: 11 | train Loss: 0.0003274769405834377 | train Accuracy: 0.9783738938053097 | train macro avg persision: {'precision': 0.9784706425884595, 'recall': 0.9783738938053096, 'f1-score': 0.9782690699946313, 'support': 36160}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.9594    0.9082    0.9331      3616\n",
      "   celebrity     0.9806    0.9909    0.9857      3616\n",
      "        plan     0.9600    0.9815    0.9706      3616\n",
      "    requests     0.9478    0.9934    0.9700      3616\n",
      "      rumors     0.9972    0.9892    0.9932      3616\n",
      "      advice     0.9981    0.9997    0.9989      3616\n",
      "restrictions     0.9997    1.0000    0.9999      3616\n",
      "    personal     0.9788    0.9563    0.9674      3616\n",
      "   unrelated     0.9820    0.9815    0.9817      3616\n",
      "      others     0.9812    0.9831    0.9822      3616\n",
      "\n",
      "    accuracy                         0.9784     36160\n",
      "   macro avg     0.9785    0.9784    0.9783     36160\n",
      "weighted avg     0.9785    0.9784    0.9783     36160\n",
      "\n",
      "\n",
      "Epochs: 11 | val Loss: 0.0082337511703372 | val Accuracy: 0.576 | val macro avg persision: {'precision': 0.34697766552909365, 'recall': 0.2808242473534155, 'f1-score': 0.28781080082271915, 'support': 1000}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.7215    0.6514    0.6847       545\n",
      "   celebrity     0.8409    0.7655    0.8014       145\n",
      "        plan     0.2031    0.1585    0.1781        82\n",
      "    requests     0.1818    0.1000    0.1290        20\n",
      "      rumors     0.2500    0.0667    0.1053        15\n",
      "      advice     0.5000    0.1000    0.1667        10\n",
      "restrictions     0.0000    0.0000    0.0000         2\n",
      "    personal     0.3279    0.6328    0.4320       128\n",
      "   unrelated     0.4444    0.3333    0.3810        36\n",
      "      others     0.0000    0.0000    0.0000        17\n",
      "\n",
      "    accuracy                         0.5760      1000\n",
      "   macro avg     0.3470    0.2808    0.2878      1000\n",
      "weighted avg     0.6022    0.5760    0.5788      1000\n",
      "\n",
      "\n",
      "Epochs: 12 | train Loss: 0.0002993160451296717 | train Accuracy: 0.9807245575221238 | train macro avg persision: {'precision': 0.980823694399669, 'recall': 0.980724557522124, 'f1-score': 0.9806513788638209, 'support': 36160}\n",
      "\n",
      "Epochs: 12 | val Loss: 0.008625244721770287 | val Accuracy: 0.56 | val macro avg persision: {'precision': 0.2671765696493464, 'recall': 0.2563937700562152, 'f1-score': 0.2577087432914524, 'support': 1000}\n",
      "\n",
      "Epochs: 13 | train Loss: 0.0002945777669083327 | train Accuracy: 0.9806969026548673 | train macro avg persision: {'precision': 0.9808357029732274, 'recall': 0.9806969026548673, 'f1-score': 0.9806415960289978, 'support': 36160}\n",
      "\n",
      "Epochs: 13 | val Loss: 0.008695046417415142 | val Accuracy: 0.574 | val macro avg persision: {'precision': 0.29117061493020574, 'recall': 0.254772541058711, 'f1-score': 0.26531101198034485, 'support': 1000}\n",
      "\n",
      "Epochs: 14 | train Loss: 0.000248014839598909 | train Accuracy: 0.9832411504424778 | train macro avg persision: {'precision': 0.9833946808084381, 'recall': 0.983241150442478, 'f1-score': 0.98319875147054, 'support': 36160}\n",
      "\n",
      "Epochs: 14 | val Loss: 0.008866684511303902 | val Accuracy: 0.571 | val macro avg persision: {'precision': 0.2794617790739138, 'recall': 0.25392848115991046, 'f1-score': 0.262752492921354, 'support': 1000}\n",
      "\n",
      "Epochs: 15 | train Loss: 0.00023760001931805164 | train Accuracy: 0.9841814159292035 | train macro avg persision: {'precision': 0.9843084285383006, 'recall': 0.9841814159292035, 'f1-score': 0.984137499718592, 'support': 36160}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15 | val Loss: 0.009128120727837086 | val Accuracy: 0.543 | val macro avg persision: {'precision': 0.25969413829231197, 'recall': 0.24462705071184293, 'f1-score': 0.24936070104438718, 'support': 1000}\n",
      "\n",
      "Epochs: 16 | train Loss: 0.00023354259610641748 | train Accuracy: 0.9838772123893805 | train macro avg persision: {'precision': 0.9839767997231281, 'recall': 0.9838772123893806, 'f1-score': 0.983828481954068, 'support': 36160}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.9771    0.9342    0.9552      3616\n",
      "   celebrity     0.9857    0.9939    0.9898      3616\n",
      "        plan     0.9787    0.9895    0.9840      3616\n",
      "    requests     0.9526    0.9903    0.9711      3616\n",
      "      rumors     0.9931    0.9900    0.9916      3616\n",
      "      advice     0.9978    1.0000    0.9989      3616\n",
      "restrictions     0.9997    1.0000    0.9999      3616\n",
      "    personal     0.9851    0.9674    0.9761      3616\n",
      "   unrelated     0.9856    0.9842    0.9849      3616\n",
      "      others     0.9843    0.9892    0.9868      3616\n",
      "\n",
      "    accuracy                         0.9839     36160\n",
      "   macro avg     0.9840    0.9839    0.9838     36160\n",
      "weighted avg     0.9840    0.9839    0.9838     36160\n",
      "\n",
      "\n",
      "Epochs: 16 | val Loss: 0.00940998550504446 | val Accuracy: 0.566 | val macro avg persision: {'precision': 0.28148454264369416, 'recall': 0.2545416513150619, 'f1-score': 0.25898193213046167, 'support': 1000}\n",
      "\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "   info_news     0.6882    0.6844    0.6863       545\n",
      "   celebrity     0.8295    0.7379    0.7810       145\n",
      "        plan     0.1127    0.0976    0.1046        82\n",
      "    requests     0.1667    0.1000    0.1250        20\n",
      "      rumors     0.0000    0.0000    0.0000        15\n",
      "      advice     0.3333    0.1000    0.1538        10\n",
      "restrictions     0.0000    0.0000    0.0000         2\n",
      "    personal     0.3316    0.4922    0.3962       128\n",
      "   unrelated     0.3529    0.3333    0.3429        36\n",
      "      others     0.0000    0.0000    0.0000        17\n",
      "\n",
      "    accuracy                         0.5660      1000\n",
      "   macro avg     0.2815    0.2545    0.2590      1000\n",
      "weighted avg     0.5664    0.5660    0.5630      1000\n",
      "\n",
      "\n",
      "Epochs: 17 | train Loss: 0.00022538813936989754 | train Accuracy: 0.9844303097345133 | train macro avg persision: {'precision': 0.9845862722196405, 'recall': 0.9844303097345133, 'f1-score': 0.9844105209882968, 'support': 36160}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 17 | val Loss: 0.009295482188463211 | val Accuracy: 0.559 | val macro avg persision: {'precision': 0.2938909539379725, 'recall': 0.25413254189782486, 'f1-score': 0.2620735481780056, 'support': 1000}\n",
      "\n",
      "Epochs: 18 | train Loss: 0.0002312069700565189 | train Accuracy: 0.9837112831858407 | train macro avg persision: {'precision': 0.9838431591255727, 'recall': 0.9837112831858408, 'f1-score': 0.9836868406769007, 'support': 36160}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 18 | val Loss: 0.009379194118082523 | val Accuracy: 0.541 | val macro avg persision: {'precision': 0.295377890278957, 'recall': 0.26935257754784125, 'f1-score': 0.27539045445407195, 'support': 1000}\n",
      "\n",
      "Epochs: 19 | train Loss: 0.00024391648184973747 | train Accuracy: 0.9826603982300885 | train macro avg persision: {'precision': 0.9827976129614303, 'recall': 0.9826603982300884, 'f1-score': 0.9826249287718343, 'support': 36160}\n",
      "\n",
      "Epochs: 19 | val Loss: 0.009657694958150387 | val Accuracy: 0.548 | val macro avg persision: {'precision': 0.2996579963146685, 'recall': 0.2622089839413104, 'f1-score': 0.2752394746952012, 'support': 1000}\n",
      "\n",
      "Epochs: 20 | train Loss: 0.00023179441632237285 | train Accuracy: 0.9838772123893805 | train macro avg persision: {'precision': 0.9840150684363582, 'recall': 0.9838772123893806, 'f1-score': 0.9838495622595348, 'support': 36160}\n",
      "\n",
      "Epochs: 20 | val Loss: 0.009658045135438442 | val Accuracy: 0.57 | val macro avg persision: {'precision': 0.2736323947656779, 'recall': 0.2446392325987282, 'f1-score': 0.254273392073595, 'support': 1000}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# batch: as bulks, bulk of sentences, each iter, update their weights each iter \n",
    "# parameters in the model apply the gradient discend (derivative of loss/weights)\n",
    "train_lstm(model, dataset_train, dataset_test, criterion, optimizer,list(category_classes.keys()) , n_classes=10, batch_size=256, epochs=20)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3 (tags/v3.10.3:a342a49, Mar 16 2022, 13:07:40) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d93ce000fb5f8fcca2dab3e75c99c50bb371be07ecadf3a0d8d467af599caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
