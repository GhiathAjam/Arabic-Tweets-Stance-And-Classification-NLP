{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prvnpGWH4q5K",
        "outputId": "ceb67b3c-1af1-4e60-8356-ace3127aeebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/Dataset.zip\n",
            "   creating: Dataset/\n",
            "  inflating: Dataset/classification_train_sample1.csv  \n",
            "  inflating: Dataset/dev.csv         \n",
            "  inflating: Dataset/duplicates.csv  \n",
            "  inflating: Dataset/stance_train_sample1.csv  \n",
            "  inflating: Dataset/train.csv       \n"
          ]
        }
      ],
      "source": [
        "# You'll only need this cell if you run this notebook on colab\n",
        "# don't forget to zip the dataset folder then upload it\n",
        "# !rm -rf Dataset\n",
        "# !unzip \"/content/Dataset.zip\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDqph7b74jTB",
        "outputId": "62c73b7d-1509-427a-f3d4-c24388f983ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting arabert\n",
            "  Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting emoji==1.4.2\n",
            "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 56.9 MB/s \n",
            "\u001b[?25hCollecting PyArabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 70.5 MB/s \n",
            "\u001b[?25hCollecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farasapy->arabert) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farasapy->arabert) (2.23.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from PyArabic->arabert) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (2022.12.7)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=a60ede614a118cc9ef13de3374a859fb2f22953ed67381c439a88cc3cf63b2d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/4d/3c/cada364d4ea0026deee7208dee1e61bcebd20aa2ae5dc154ba\n",
            "Successfully built emoji\n",
            "Installing collected packages: PyArabic, farasapy, emoji, arabert\n",
            "Successfully installed PyArabic-0.6.15 arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install arabert\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aayXYZGd4jTG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "# Can use this library to reload a specific module if the notebook can't see changes in the imported module\n",
        "import importlib\n",
        "import utils\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from bert import AraBERTDataset, BertClassifier, train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYX9P6GC4jTH"
      },
      "source": [
        "Stance detection labels meaning is as follows:\n",
        "1. Positive (1): means that the tweet author encourages and supports vaccination.\n",
        "2. Negative (-1): means that the tweet author refuses vaccination.\n",
        "3. Neutral (0): means that the tweet neither supports nor refuses vaccination.\n",
        "\n",
        "Category labels meaning is as follows:\n",
        "1. Info_News: Information about vaccination.\n",
        "2. Celebrities: mentioning celebrities taking vaccinations.\n",
        "3. Plan: Governmental plan or progress of vaccination.\n",
        "4. Request: Requests from governments regarding the vaccination process.\n",
        "5. Rumor: the tweet is a rumor.\n",
        "6. Advice: Advice related to the virus or the vaccination\n",
        "7. Restriction: Restrictions due to the virus e.g. traveling.\n",
        "8. Personal: Personal opinion or story about vaccination.\n",
        "9. Unrelated: Unrelated to vaccination.\n",
        "10.Others: Vaccination related but not one of the above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yE2_sx7o4jTJ",
        "outputId": "4276a580-dc90-4124-b8ee-0ecd0914b0bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1e35258-8565-4e0b-8ae0-996275979b94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1e35258-8565-4e0b-8ae0-996275979b94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1e35258-8565-4e0b-8ae0-996275979b94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1e35258-8565-4e0b-8ae0-996275979b94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  stance\n",
              "0  بيل غيتس يتلقى لقاح #كوفيد19 من غير تصوير الاب...       1\n",
              "1  وزير الصحة لحد اليوم وتحديدا هلأ بمؤتمروا الصح...       1\n",
              "2  قولكن  رح يكونو اد المسؤولية ب لبنان لما يوصل ...       1\n",
              "3  #تركيا.. وزير الصحة فخر الدين قوجة يتلقى أول ج...       1\n",
              "4  وئام وهاب يشتم الدول الخليجية في كل طلة اعلامي...       0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = pd.read_csv('./Dataset/stance_train_sample1.csv')\n",
        "d = pd.read_csv('./Dataset/dev.csv')\n",
        "\n",
        "t.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4HAmB0PK6hF",
        "outputId": "a2b7d07d-678c-4d17-dddb-176bdeb5cd9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16614 entries, 0 to 16613\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    16614 non-null  object\n",
            " 1   stance  16614 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 259.7+ KB\n",
            "None\n",
            "####################################\n",
            "counts for each stance label :\n",
            " 1    0.333333\n",
            " 0    0.333333\n",
            "-1    0.333333\n",
            "Name: stance, dtype: float64\n",
            " 1    0.804\n",
            " 0    0.126\n",
            "-1    0.070\n",
            "Name: stance, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# analyze dataset\n",
        "print(t.info())\n",
        "# d\n",
        "# print(d.info())\n",
        "\n",
        "# count for stance labels\n",
        "print(\"####################################\")\n",
        "print(\"counts for each stance label :\")\n",
        "print(t['stance'].value_counts(normalize=True))\n",
        "# d\n",
        "print(d['stance'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ligkefdf4jTV"
      },
      "source": [
        "## AraBERT model\n",
        "- We will use aubmindlab/bert-base-arabertv02-twitter\n",
        "- It's pre-trained on ~60M arabic tweets, and it encluded emojis in the training. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_yE3LOsy-Ts"
      },
      "source": [
        "#### Preprocess Data for Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hgkKWE5R4jTN"
      },
      "outputs": [],
      "source": [
        "# seperate train data from their labels\n",
        "X = t['text']\n",
        "\n",
        "Ys = t['stance']\n",
        "# needed to map classes_ids from -1, 0, 1 to 2, 0, 1 since model gave error when received a negative label.\n",
        "Ys = Ys.replace(utils.stance_classes_reverse)\n",
        "Ys = Ys.replace(utils.stance_classes)\n",
        "\n",
        "# Yc = t['category']\n",
        "# Yc = Yc.replace(utils.category_classes)\n",
        "\n",
        "# seperate validation data from their labels\n",
        "X_val = d['text']\n",
        "\n",
        "Ys_val = d['stance']\n",
        "Ys_val = Ys_val.replace(utils.stance_classes_reverse)\n",
        "Ys_val = Ys_val.replace(utils.stance_classes)\n",
        "\n",
        "# Yc_val = d['category']\n",
        "# Yc = Yc_val.replace(utils.category_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko0xeSOe0rRZ"
      },
      "source": [
        "#### Create Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izAbUUp94jTZ",
        "outputId": "e044080a-22e5-4f73-e3cf-6c0598d51946"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "model_name=\"aubmindlab/bert-base-arabertv02-twitter\"\n",
        "\n",
        "# load the preprocessing function they used to train their data on.\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "X = X.apply(arabert_prep.preprocess)\n",
        "X_val = X_val.apply(arabert_prep.preprocess)\n",
        "\n",
        "# instantiate train and validation datasets\n",
        "train_dataset = AraBERTDataset(X, Ys, model_name)\n",
        "val_dataset = AraBERTDataset(X_val, Ys_val, model_name)\n",
        "\n",
        "# create model\n",
        "model = BertClassifier(model_name, n_classes=3)\n",
        "\n",
        "# make the criterion cross entropy loss\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# create the optimizer (Adam)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCRFoiWa0n4z"
      },
      "source": [
        "#### Train Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAdvUGZV4jTb",
        "outputId": "8109a20f-5d9a-4c57-cf0a-62ced60ffe62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | train Loss: 0.027544759213924408 | train Accuracy: 0.824605754183219 | train macro avg persision: {'precision': 0.829423225054136, 'recall': 0.824605754183219, 'f1-score': 0.8231636013332834, 'support': 16614}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.7921    0.8044    0.7982      5538\n",
            "    Positive     0.8899    0.7385    0.8072      5538\n",
            "    Negative     0.8062    0.9308    0.8641      5538\n",
            "\n",
            "    accuracy                         0.8246     16614\n",
            "   macro avg     0.8294    0.8246    0.8232     16614\n",
            "weighted avg     0.8294    0.8246    0.8232     16614\n",
            "\n",
            "\n",
            "Epochs: 1 | val Loss: 0.04101259261369705 | val Accuracy: 0.748 | val macro avg persision: {'precision': 0.5642344461828628, 'recall': 0.7105306799336649, 'f1-score': 0.6003108329925199, 'support': 1000}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.3717    0.6667    0.4773       126\n",
            "    Positive     0.9685    0.7649    0.8548       804\n",
            "    Negative     0.3525    0.7000    0.4689        70\n",
            "\n",
            "    accuracy                         0.7480      1000\n",
            "   macro avg     0.5642    0.7105    0.6003      1000\n",
            "weighted avg     0.8502    0.7480    0.7802      1000\n",
            "\n",
            "\n",
            "Epochs: 2 | train Loss: 0.02772817388176918 | train Accuracy: 0.8208137715179968 | train macro avg persision: {'precision': 0.825779110419414, 'recall': 0.820813771517997, 'f1-score': 0.8191056142107458, 'support': 16614}\n",
            "\n",
            "Epochs: 2 | val Loss: 0.038720160722732544 | val Accuracy: 0.782 | val macro avg persision: {'precision': 0.5793434474140996, 'recall': 0.6875029613835584, 'f1-score': 0.6146385126760973, 'support': 1000}\n",
            "\n",
            "Epochs: 3 | train Loss: 0.02730393409729004 | train Accuracy: 0.8278560250391236 | train macro avg persision: {'precision': 0.8324506696247086, 'recall': 0.8278560250391237, 'f1-score': 0.8262637604162738, 'support': 16614}\n",
            "\n",
            "Epochs: 3 | val Loss: 0.041047267615795135 | val Accuracy: 0.772 | val macro avg persision: {'precision': 0.5760887685860946, 'recall': 0.6965134644239122, 'f1-score': 0.6129167503354763, 'support': 1000}\n",
            "\n",
            "Epochs: 4 | train Loss: 0.027613572776317596 | train Accuracy: 0.8252076561935717 | train macro avg persision: {'precision': 0.8295840032429486, 'recall': 0.8252076561935717, 'f1-score': 0.8236798546896459, 'support': 16614}\n",
            "\n",
            "Epochs: 4 | val Loss: 0.043145276606082916 | val Accuracy: 0.757 | val macro avg persision: {'precision': 0.5740137316337877, 'recall': 0.7144910368790965, 'f1-score': 0.6118383906062117, 'support': 1000}\n",
            "\n",
            "Epochs: 5 | train Loss: 0.026827987283468246 | train Accuracy: 0.8280365956422294 | train macro avg persision: {'precision': 0.8327648502642738, 'recall': 0.8280365956422294, 'f1-score': 0.8264768807202887, 'support': 16614}\n",
            "\n",
            "Epochs: 5 | val Loss: 0.04039915278553963 | val Accuracy: 0.772 | val macro avg persision: {'precision': 0.5714997147271789, 'recall': 0.6766642975598199, 'f1-score': 0.6055838001456524, 'support': 1000}\n",
            "\n",
            "Epochs: 6 | train Loss: 0.02684694342315197 | train Accuracy: 0.8315878175033105 | train macro avg persision: {'precision': 0.8360603075999746, 'recall': 0.8315878175033103, 'f1-score': 0.8301382551940164, 'support': 16614}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.7936    0.8194    0.8063      5538\n",
            "    Positive     0.8939    0.7409    0.8102      5538\n",
            "    Negative     0.8206    0.9345    0.8739      5538\n",
            "\n",
            "    accuracy                         0.8316     16614\n",
            "   macro avg     0.8361    0.8316    0.8301     16614\n",
            "weighted avg     0.8361    0.8316    0.8301     16614\n",
            "\n",
            "\n",
            "Epochs: 6 | val Loss: 0.0406184084713459 | val Accuracy: 0.764 | val macro avg persision: {'precision': 0.56798022928926, 'recall': 0.7016623233041143, 'f1-score': 0.6044936726079512, 'support': 1000}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.4051    0.6270    0.4922       126\n",
            "    Positive     0.9608    0.7923    0.8684       804\n",
            "    Negative     0.3380    0.6857    0.4528        70\n",
            "\n",
            "    accuracy                         0.7640      1000\n",
            "   macro avg     0.5680    0.7017    0.6045      1000\n",
            "weighted avg     0.8472    0.7640    0.7919      1000\n",
            "\n",
            "\n",
            "Epochs: 7 | train Loss: 0.027009837329387665 | train Accuracy: 0.8262910798122066 | train macro avg persision: {'precision': 0.8308747032995413, 'recall': 0.8262910798122066, 'f1-score': 0.8249029057022182, 'support': 16614}\n",
            "\n",
            "Epochs: 7 | val Loss: 0.040955521166324615 | val Accuracy: 0.761 | val macro avg persision: {'precision': 0.5652530311893543, 'recall': 0.6896075179657268, 'f1-score': 0.6008797982692109, 'support': 1000}\n",
            "\n",
            "Epochs: 8 | train Loss: 0.027059441432356834 | train Accuracy: 0.8248465149873601 | train macro avg persision: {'precision': 0.8297266356944943, 'recall': 0.82484651498736, 'f1-score': 0.823391055977497, 'support': 16614}\n",
            "\n",
            "Epochs: 8 | val Loss: 0.040211841464042664 | val Accuracy: 0.773 | val macro avg persision: {'precision': 0.5791861629070931, 'recall': 0.712086393429677, 'f1-score': 0.6175700900733053, 'support': 1000}\n",
            "\n",
            "Epochs: 9 | train Loss: 0.026963287964463234 | train Accuracy: 0.8247261345852895 | train macro avg persision: {'precision': 0.8298124440997436, 'recall': 0.8247261345852895, 'f1-score': 0.8231575900745544, 'support': 16614}\n",
            "\n",
            "Epochs: 9 | val Loss: 0.042332179844379425 | val Accuracy: 0.771 | val macro avg persision: {'precision': 0.5781704636771265, 'recall': 0.7024480770749427, 'f1-score': 0.61618753875973, 'support': 1000}\n",
            "\n",
            "Epochs: 10 | train Loss: 0.026525508612394333 | train Accuracy: 0.8271337426267004 | train macro avg persision: {'precision': 0.8312825313573601, 'recall': 0.8271337426267005, 'f1-score': 0.8255746862791891, 'support': 16614}\n",
            "\n",
            "Epochs: 10 | val Loss: 0.04040592536330223 | val Accuracy: 0.77 | val macro avg persision: {'precision': 0.5768232427748844, 'recall': 0.6978006791439627, 'f1-score': 0.6141390027168303, 'support': 1000}\n",
            "\n",
            "Epochs: 11 | train Loss: 0.02669559232890606 | train Accuracy: 0.834597327555074 | train macro avg persision: {'precision': 0.8388950230497881, 'recall': 0.8345973275550739, 'f1-score': 0.833234049520812, 'support': 16614}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.8054    0.8183    0.8118      5538\n",
            "    Positive     0.8948    0.7495    0.8158      5538\n",
            "    Negative     0.8165    0.9359    0.8721      5538\n",
            "\n",
            "    accuracy                         0.8346     16614\n",
            "   macro avg     0.8389    0.8346    0.8332     16614\n",
            "weighted avg     0.8389    0.8346    0.8332     16614\n",
            "\n",
            "\n",
            "Epochs: 11 | val Loss: 0.04291796684265137 | val Accuracy: 0.78 | val macro avg persision: {'precision': 0.581986919602241, 'recall': 0.7017176024638712, 'f1-score': 0.6197891516297718, 'support': 1000}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.4149    0.6190    0.4968       126\n",
            "    Positive     0.9520    0.8147    0.8780       804\n",
            "    Negative     0.3790    0.6714    0.4845        70\n",
            "\n",
            "    accuracy                         0.7800      1000\n",
            "   macro avg     0.5820    0.7017    0.6198      1000\n",
            "weighted avg     0.8442    0.7800    0.8024      1000\n",
            "\n",
            "\n",
            "Epochs: 12 | train Loss: 0.026656124740839005 | train Accuracy: 0.8260503190080655 | train macro avg persision: {'precision': 0.8309152310970997, 'recall': 0.8260503190080654, 'f1-score': 0.8245271456751618, 'support': 16614}\n",
            "\n",
            "Epochs: 12 | val Loss: 0.04308779165148735 | val Accuracy: 0.775 | val macro avg persision: {'precision': 0.5834842437480116, 'recall': 0.7086827765932243, 'f1-score': 0.621982326161581, 'support': 1000}\n",
            "\n",
            "Epochs: 13 | train Loss: 0.026652049273252487 | train Accuracy: 0.8297821114722523 | train macro avg persision: {'precision': 0.8346522546155871, 'recall': 0.8297821114722522, 'f1-score': 0.8280721739986564, 'support': 16614}\n",
            "\n",
            "Epochs: 13 | val Loss: 0.0442478284239769 | val Accuracy: 0.762 | val macro avg persision: {'precision': 0.5685491580338842, 'recall': 0.6944839295585564, 'f1-score': 0.6044685583625372, 'support': 1000}\n",
            "\n",
            "Epochs: 14 | train Loss: 0.026875626295804977 | train Accuracy: 0.827073552425665 | train macro avg persision: {'precision': 0.8315431307338987, 'recall': 0.8270735524256652, 'f1-score': 0.8254385962329106, 'support': 16614}\n",
            "\n",
            "Epochs: 14 | val Loss: 0.04177000746130943 | val Accuracy: 0.764 | val macro avg persision: {'precision': 0.5735960848404628, 'recall': 0.6910803127221037, 'f1-score': 0.6079914135123641, 'support': 1000}\n",
            "\n",
            "Epochs: 15 | train Loss: 0.02679130621254444 | train Accuracy: 0.8309859154929577 | train macro avg persision: {'precision': 0.8356440788057405, 'recall': 0.8309859154929576, 'f1-score': 0.8294860783472426, 'support': 16614}\n",
            "\n",
            "Epochs: 15 | val Loss: 0.042041052132844925 | val Accuracy: 0.771 | val macro avg persision: {'precision': 0.5819005147389053, 'recall': 0.707138908631446, 'f1-score': 0.619169809941771, 'support': 1000}\n",
            "\n",
            "Epochs: 16 | train Loss: 0.026142096146941185 | train Accuracy: 0.8329120019260864 | train macro avg persision: {'precision': 0.8373417068721611, 'recall': 0.8329120019260864, 'f1-score': 0.8313460565873402, 'support': 16614}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.7972    0.8205    0.8087      5538\n",
            "    Positive     0.8940    0.7400    0.8097      5538\n",
            "    Negative     0.8209    0.9382    0.8756      5538\n",
            "\n",
            "    accuracy                         0.8329     16614\n",
            "   macro avg     0.8373    0.8329    0.8313     16614\n",
            "weighted avg     0.8373    0.8329    0.8313     16614\n",
            "\n",
            "\n",
            "Epochs: 16 | val Loss: 0.0453588142991066 | val Accuracy: 0.762 | val macro avg persision: {'precision': 0.5706594911003648, 'recall': 0.7138750690989496, 'f1-score': 0.6075649163496789, 'support': 1000}\n",
            "\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "     Neutral     0.4225    0.6270    0.5048       126\n",
            "    Positive     0.9605    0.7861    0.8646       804\n",
            "    Negative     0.3290    0.7286    0.4533        70\n",
            "\n",
            "    accuracy                         0.7620      1000\n",
            "   macro avg     0.5707    0.7139    0.6076      1000\n",
            "weighted avg     0.8485    0.7620    0.7905      1000\n",
            "\n",
            "\n",
            "Epochs: 17 | train Loss: 0.02603696845471859 | train Accuracy: 0.833032382328157 | train macro avg persision: {'precision': 0.8368791026279917, 'recall': 0.8330323823281569, 'f1-score': 0.8313885654702674, 'support': 16614}\n",
            "\n",
            "Epochs: 17 | val Loss: 0.042526621371507645 | val Accuracy: 0.767 | val macro avg persision: {'precision': 0.5757329950248824, 'recall': 0.707596935955145, 'f1-score': 0.6136381527664618, 'support': 1000}\n",
            "\n",
            "Epochs: 18 | train Loss: 0.02666984498500824 | train Accuracy: 0.8294209702660407 | train macro avg persision: {'precision': 0.8337408606087285, 'recall': 0.8294209702660407, 'f1-score': 0.827954616280491, 'support': 16614}\n",
            "\n",
            "Epochs: 18 | val Loss: 0.04379648342728615 | val Accuracy: 0.769 | val macro avg persision: {'precision': 0.5730161751116979, 'recall': 0.7037352917949932, 'f1-score': 0.6106085658982109, 'support': 1000}\n",
            "\n",
            "Epochs: 19 | train Loss: 0.026221366599202156 | train Accuracy: 0.8318887685084868 | train macro avg persision: {'precision': 0.8363662712333136, 'recall': 0.8318887685084868, 'f1-score': 0.830242209929128, 'support': 16614}\n",
            "\n",
            "Epochs: 19 | val Loss: 0.0403677336871624 | val Accuracy: 0.788 | val macro avg persision: {'precision': 0.5879114843653851, 'recall': 0.6921069256890152, 'f1-score': 0.6234886826837496, 'support': 1000}\n",
            "\n",
            "Epochs: 20 | train Loss: 0.02654057741165161 | train Accuracy: 0.827494883832912 | train macro avg persision: {'precision': 0.8316861130887104, 'recall': 0.827494883832912, 'f1-score': 0.8258587302305452, 'support': 16614}\n",
            "\n",
            "Epochs: 20 | val Loss: 0.04028280824422836 | val Accuracy: 0.789 | val macro avg persision: {'precision': 0.5878573222197921, 'recall': 0.7054489457474532, 'f1-score': 0.6247232669575683, 'support': 1000}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Trianing for stance detection\n",
        "train(model, train_dataset, val_dataset, criterion=criterion, optimizer=optimizer, classes_names=list(utils.stance_classes.keys()), n_classes=3, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "R2C9AKaQL-zR"
      },
      "outputs": [],
      "source": [
        "def saveCheckpoint(filename, model, optimizer, batchsize):\n",
        "    checkpoint = {\n",
        "        'model': model,\n",
        "        'optimizer': optimizer,\n",
        "        \"batch_size\": batchsize,\n",
        "    }\n",
        "\n",
        "    # uncomment the folowing line to save all both model and optimizer state\n",
        "    torch.save(checkpoint, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo5FtRovMlZh",
        "outputId": "7a1f7acf-356d-420d-8669-3b71613c4820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C1R_BSjTMiaW"
      },
      "outputs": [],
      "source": [
        "# saveCheckpoint('/content/drive/MyDrive/NLP/60_micro_avg.pt', model, optimizer, 16)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
