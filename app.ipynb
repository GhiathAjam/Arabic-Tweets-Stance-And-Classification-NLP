{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAtXrxn0wLHQ",
        "outputId": "363ff52a-fd8b-4455-e5d4-f8e3b2d5f62d"
      },
      "outputs": [],
      "source": [
        "# !pip install camel-tools==1.2.0 farasapy nltk Arabic-Stopwords scikit-learn gensim pandas\n",
        "# !camel_data light\n",
        "# import nltk\n",
        "# nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xFMDvRawLHU",
        "outputId": "16e09e88-4a9a-4504-f6be-969a0855c945"
      },
      "outputs": [],
      "source": [
        "# built in modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from sklearn import metrics \n",
        "\n",
        "# .py files \n",
        "from preprocess import Preprocess\n",
        "from feature_extraction import *\n",
        "\n",
        "from classical_models import *\n",
        "# Can use this library to reload a specific module if the notebook can't see changes in the imported module\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mujwAMBwLHY"
      },
      "source": [
        "Stance detection labels meaning is as follows:\n",
        "1. Positive (1): means that the tweet author encourages and supports vaccination.\n",
        "2. Negative (-1): means that the tweet author refuses vaccination.\n",
        "3. Neutral (0): means that the tweet neither supports nor refuses vaccination.\n",
        "\n",
        "Category labels meaning is as follows:\n",
        "1. Info_News: Information about vaccination.\n",
        "2. Celebrities: mentioning celebrities taking vaccinations.\n",
        "3. Plan: Governmental plan or progress of vaccination.\n",
        "4. Request: Requests from governments regarding the vaccination process.\n",
        "5. Rumor: the tweet is a rumor.\n",
        "6. Advice: Advice related to the virus or the vaccination\n",
        "7. Restriction: Restrictions due to the virus e.g. traveling.\n",
        "8. Personal: Personal opinion or story about vaccination.\n",
        "9. Unrelated: Unrelated to vaccination.\n",
        "10.Others: Vaccination related but not one of the above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SnUyQbwqwLHa"
      },
      "outputs": [],
      "source": [
        "# !unzip Dataset.zip\n",
        "t = pd.read_csv('./Dataset/train.csv')\n",
        "d = pd.read_csv('./Dataset/dev.csv')\n",
        "# ts = pd.read_csv('./Dataset/test.csv')\n",
        "#\n",
        "# ov = pd.read_csv('/content/Dataset/classification_train_sample1.csv')\n",
        "# ov2 = pd.read_csv('/content/Dataset/cat_somesample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Psk40WbSwLHa"
      },
      "outputs": [],
      "source": [
        "categories = [\"info_news\", \"celebrity\", \"plan\", \"requests\", \"rumors\", \"advice\", \"restrictions\", \"personal\", \"unrelated\", \"others\"]\n",
        "def encode_category(y):\n",
        "    '''\n",
        "    Input: y a list of string labels for the category of each document \n",
        "    Output: a list of encoded 10 sized array for the category of each doc \n",
        "            for \"other\" category , it has an array =[0 0 0 0 0 0 0 0 0 1] \n",
        "    '''\n",
        "    return [categories.index(ele) for ele in y]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN-cQ0ezwLHb"
      },
      "source": [
        "### Understanding the Data\n",
        "- 80% tweets are positive (class 1), the rest are neutral and negative.\n",
        "- 50% tweets belongs to info_news category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WVr90KoqwLHb"
      },
      "outputs": [],
      "source": [
        "# # analyze dataset\n",
        "# print(\"counts for each lablel :\")\n",
        "# print(t['category'].value_counts(normalize=True))\n",
        "# print(ov['category'].value_counts(normalize=True))\n",
        "# print(ov2['category'].value_counts(normalize=True))\n",
        "# print(d['category'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NxBYW9D9wLHb"
      },
      "outputs": [],
      "source": [
        "# print(\"####################################\")\n",
        "# print(\"duplicated rows :\")\n",
        "# print(t[t.duplicated()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0VbngOOrwLHc"
      },
      "outputs": [],
      "source": [
        "X_train = t['text']\n",
        "# X_trainov = ov['text']\n",
        "# X_trainov2 = ov2['text']\n",
        "X_dev = d['text']\n",
        "# X_test = ts['text']\n",
        "#\n",
        "Y_train = t[['stance', 'category']]\n",
        "# Y_trainov = ov['category']\n",
        "# Y_trainov2 = ov2['category']\n",
        "Y_dev = d[['stance', 'category']]\n",
        "# Y_test = ts['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfpneJGawLHc"
      },
      "source": [
        "#### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "8_tOO97iwLHc",
        "outputId": "98d05733-f774-4ea6-9ade-3b20194d5b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bert MODE False\n",
            "Emojis:  raw\n"
          ]
        }
      ],
      "source": [
        "preprocess = Preprocess()\n",
        "X_train = X_train.apply(preprocess.do_all)\n",
        "# X_trainov = X_trainov.apply(preprocess.do_all)\n",
        "# X_trainov2 = X_trainov2.apply(preprocess.do_all)\n",
        "X_dev = X_dev.apply(preprocess.do_all)\n",
        "# X_test = X_test.apply(preprocess.do_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xeh9AGOywLHd"
      },
      "outputs": [],
      "source": [
        "# r = random.randint(0, len(X_test))\n",
        "# # r = 900\n",
        "# print(r, '\\n')\n",
        "# print(ts.text[r], '\\n')\n",
        "# print(X_test[r], '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EWM3pqe4wLHd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "471829\n",
            "31411\n"
          ]
        }
      ],
      "source": [
        "# Print Vocabulary size\n",
        "lst = [word for x in X_train for word in x]\n",
        "vocab = set(lst)\n",
        "print(len(lst))\n",
        "print(len(vocab))\n",
        "# print(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mgtuT2cwLHe"
      },
      "source": [
        "### Getting the train , test and dev features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a6k8I67QwLHe"
      },
      "outputs": [],
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# vectorizer =TfidfVectorizer(analyzer=lambda x: x)\n",
        "# train_features= vectorizer.fit_transform(X)\n",
        "# # return train_features.toarray(), test_features.toarray()\n",
        "\n",
        "# # print 10 words with highest tfidf values for each CATEGORY\n",
        "# feature_names = vectorizer.get_feature_names_out()\n",
        "# for i, category in enumerate(categories):\n",
        "#     lst = [0] *len(feature_names)\n",
        "#     for row in train_features[np.array(yc) == i].toarray():\n",
        "#         lst = [x + y for x, y in zip(lst, row)]\n",
        "#     # top 10 words\n",
        "#     top20 = np.argsort(lst)[::-1][:20]\n",
        "#     # print names and values\n",
        "#     print(category)\n",
        "#     print([(feature_names[j], lst[j]) for j in top20])\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1kzMYg4wLHf"
      },
      "source": [
        "## Classical model Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYdn4HKAwLHg"
      },
      "source": [
        "- Classification Task Results:\n",
        "\n",
        "|  | SVM | Random Forest | KNN |  Voting system |\n",
        "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
        "| TFIDF |69%  |  |  ||\n",
        "| BOW | 54%  |   |   | |\n",
        "\n",
        "\n",
        "- Stance Task Results:\n",
        "\n",
        "|  | SVM | Random Forest | KNN |  Voting system |\n",
        "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
        "| TFIDF |81%  |  |  ||\n",
        "| BOW | 80%  |   |   | |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "USifXj_ywLHg"
      },
      "outputs": [],
      "source": [
        "def get_TFIDF(tr,ts):\n",
        "    trw, tsw = TFIDF(tr, ts, 'word', 1, 2)\n",
        "    trc, tsc = TFIDF(tr, ts, 'char', 2, 3)\n",
        "    return np.concatenate((trw, trc), axis=1), np.concatenate((tsw, tsc), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koGPvwYh2_2T",
        "outputId": "1710d48e-24d7-41f8-e70d-02a75e26978c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NBmodel\n",
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        70\n",
            "           0       0.23      0.72      0.35       126\n",
            "           1       0.89      0.67      0.76       804\n",
            "\n",
            "    accuracy                           0.63      1000\n",
            "   macro avg       0.37      0.46      0.37      1000\n",
            "weighted avg       0.74      0.63      0.66      1000\n",
            "\n",
            "KNNmodel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.05      0.01      0.02        70\n",
            "           0       0.20      0.25      0.22       126\n",
            "           1       0.81      0.84      0.83       804\n",
            "\n",
            "    accuracy                           0.71      1000\n",
            "   macro avg       0.36      0.37      0.36      1000\n",
            "weighted avg       0.68      0.71      0.69      1000\n",
            "\n",
            "LSVMmodel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.17      0.01      0.03        70\n",
            "           0       0.50      0.02      0.03       126\n",
            "           1       0.81      1.00      0.89       804\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.49      0.34      0.32      1000\n",
            "weighted avg       0.73      0.80      0.72      1000\n",
            "\n",
            "LRmodel\n",
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.08      1.00      0.14        70\n",
            "           0       0.00      0.00      0.00       126\n",
            "           1       1.00      0.12      0.21       804\n",
            "\n",
            "    accuracy                           0.16      1000\n",
            "   macro avg       0.36      0.37      0.12      1000\n",
            "weighted avg       0.81      0.16      0.18      1000\n",
            "\n",
            "RGmodel\n",
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        70\n",
            "           0       0.44      0.25      0.31       126\n",
            "           1       0.83      0.96      0.89       804\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.42      0.40      0.40      1000\n",
            "weighted avg       0.72      0.80      0.75      1000\n",
            "\n",
            "RFmodel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        70\n",
            "           0       0.00      0.00      0.00       126\n",
            "           1       0.80      1.00      0.89       804\n",
            "\n",
            "    accuracy                           0.80      1000\n",
            "   macro avg       0.27      0.33      0.30      1000\n",
            "weighted avg       0.65      0.80      0.72      1000\n",
            "\n",
            "DTmodel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Stance =========\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00        70\n",
            "           0       0.11      0.02      0.03       126\n",
            "           1       0.79      0.89      0.83       804\n",
            "\n",
            "    accuracy                           0.71      1000\n",
            "   macro avg       0.30      0.30      0.29      1000\n",
            "weighted avg       0.65      0.71      0.67      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# train_features, test_features = get_TFIDF(X_train, X_dev)\n",
        "train_features, test_features = SG(X_train, X_dev)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "clss = [NBmodel, KNNmodel, LSVMmodel, LRmodel, RGmodel, RFmodel, DTmodel]\n",
        "# clss = [SVMmodel]\n",
        "# clss = [KNNmodel]\n",
        "#\n",
        "for cls in clss:\n",
        "    #\n",
        "    print(cls.__name__)\n",
        "    # yc_pred = cls(Xtrain=train_features, y_train=Y_train['category'], X_test=test_features)\n",
        "    ys_pred = cls(Xtrain=train_features, y_train=Y_train['stance'], X_test=test_features)\n",
        "    #\n",
        "    # print('========= Category =========')\n",
        "    # print(metrics.classification_report(y_true=Y_dev['category'],y_pred=yc_pred))\n",
        "    print('========= Stance =========')\n",
        "    print(metrics.classification_report(y_true=Y_dev['stance'],y_pred=ys_pred))\n",
        "\n",
        "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
        "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prediction of Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmjFw6Of52dU",
        "outputId": "9356e8be-000f-49d5-a20e-388f086c1ef6"
      },
      "outputs": [],
      "source": [
        "# get output of test set\n",
        "X_train_dev = np.concatenate((X_train, X_dev), axis=0)\n",
        "Y_train_dev = np.concatenate((Y_train, Y_dev), axis=0)\n",
        "print(X_train.shape, X_dev.shape, X_train_dev.shape)\n",
        "print(Y_train_dev.shape)\n",
        "train_features, test_features = TFIDF(X_train_dev, X_test)\n",
        "\n",
        "yc_pred = LSVMmodel(Xtrain=train_features, y_train=Y_train_dev, X_test=test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD8u_6tm6_Rh",
        "outputId": "dccb94d5-1eb1-4c51-b3d0-a1d867ce424a"
      },
      "outputs": [],
      "source": [
        "# yc_pred\n",
        "pred = [(i, vi) for i, vi in enumerate(yc_pred)]\n",
        "\n",
        "print(pred[:15])\n",
        "# print(pred.value_counts())\n",
        "# print(metrics.classification_report(labels, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Saving model to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBXI2pG60xxH",
        "outputId": "40c8751e-515e-470d-8507-72864bd8dc6d"
      },
      "outputs": [],
      "source": [
        "# from sklearn import svm\n",
        "# clf=svm.LinearSVC(class_weight='balanced')\n",
        "# clf.fit(X=train_features,y=Y_train_dev)\n",
        "\n",
        "# from joblib import dump, load\n",
        "# dump(clf, 'filename.joblib') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Writing output to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlTBf9vC7Vjd"
      },
      "outputs": [],
      "source": [
        "# import csv\n",
        "# with open('./out/test_cat.csv', \"w\",encoding=\"utf-8\", newline='') as f:\n",
        "#     writer = csv.writer(f)\n",
        "#     writer.writerow(('id','stance'))\n",
        "#     for row in pred:\n",
        "#         writer.writerow(row)\n",
        "\n",
        "# dd = pd.read_csv('./out/test_cat.csv')\n",
        "# print(dd.head())\n",
        "\n",
        "# print(dd.stance.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJB5b_IuwLHh"
      },
      "outputs": [],
      "source": [
        "asds"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
