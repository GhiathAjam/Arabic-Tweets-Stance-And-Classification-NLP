{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !camel_data light\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in modules\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics \n",
    "\n",
    "# .py files \n",
    "from preprocess import Preprocess\n",
    "from feature_extraction import BOW\n",
    "from feature_extraction import TFIDF\n",
    "from feature_extraction import CBOW\n",
    "from feature_extraction import SG\n",
    "\n",
    "from classical_models import SVMmodel\n",
    "# Can use this library to reload a specific module if the notebook can't see changes in the imported module\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stance detection labels meaning is as follows:\n",
    "1. Positive (1): means that the tweet author encourages and supports vaccination.\n",
    "2. Negative (-1): means that the tweet author refuses vaccination.\n",
    "3. Neutral (0): means that the tweet neither supports nor refuses vaccination.\n",
    "\n",
    "Category labels meaning is as follows:\n",
    "1. Info_News: Information about vaccination.\n",
    "2. Celebrities: mentioning celebrities taking vaccinations.\n",
    "3. Plan: Governmental plan or progress of vaccination.\n",
    "4. Request: Requests from governments regarding the vaccination process.\n",
    "5. Rumor: the tweet is a rumor.\n",
    "6. Advice: Advice related to the virus or the vaccination\n",
    "7. Restriction: Restrictions due to the virus e.g. traveling.\n",
    "8. Personal: Personal opinion or story about vaccination.\n",
    "9. Unrelated: Unrelated to vaccination.\n",
    "10.Others: Vaccination related but not one of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('./Dataset/train.csv')\n",
    "d = pd.read_csv('./Dataset/dev.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emojis:  True\n",
      "Lemmatizor:  camel\n"
     ]
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "#\n",
    "categories = [\"info_news\", \"celebrity\", \"plan\", \"requests\", \"rumors\", \"advice\", \"restrictions\", \"personal\", \"unrelated\", \"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 9 categories so we have an array of len 9 for each y\n",
    "def encode_category(y):\n",
    "    '''\n",
    "    Input: y a list of string labels for the category of each document \n",
    "    Output: a list of encoded 10 sized array for the category of each doc \n",
    "            for \"other\" category , it has an array =[0 0 0 0 0 0 0 0 0 1] \n",
    "    '''\n",
    "    return [categories.index(ele) for ele in y]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data\n",
    "- 80% tweets are positive (class 1), the rest are neutral and negative.\n",
    "- 50% tweets belongs to info_news category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6988 entries, 0 to 6987\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      6988 non-null   object\n",
      " 1   category  6988 non-null   object\n",
      " 2   stance    6988 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 163.9+ KB\n",
      "None\n",
      "####################################\n",
      "counts for each lablel :\n",
      "info_news       0.517459\n",
      "personal        0.146680\n",
      "celebrity       0.139525\n",
      "plan            0.086720\n",
      "unrelated       0.046222\n",
      "others          0.023898\n",
      "requests        0.016027\n",
      "rumors          0.011305\n",
      "advice          0.009588\n",
      "restrictions    0.002576\n",
      "Name: category, dtype: float64\n",
      "####################################\n",
      "counts for each stance label :\n",
      " 1    0.792501\n",
      " 0    0.144820\n",
      "-1    0.062679\n",
      "Name: stance, dtype: float64\n",
      " 1    0.804\n",
      " 0    0.126\n",
      "-1    0.070\n",
      "Name: stance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# analyze dataset\n",
    "print(t.info())\n",
    "# d\n",
    "# print(d.info())\n",
    "\n",
    "# count for each label\n",
    "print(\"####################################\")\n",
    "print(\"counts for each lablel :\")\n",
    "print(t['category'].value_counts(normalize=True))\n",
    "# same for d\n",
    "# print(d['category'].value_counts(normalize=True))\n",
    "\n",
    "# count for stance labels\n",
    "print(\"####################################\")\n",
    "print(\"counts for each stance label :\")\n",
    "print(t['stance'].value_counts(normalize=True))\n",
    "# d\n",
    "print(d['stance'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t['text']\n",
    "ys = t['stance']\n",
    "yc = t['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "duplicated rows :\n",
      "                                                   text   category  stance\n",
      "529   اللقاح لازم ينحفظ بدرجة حرارة ٧٠ دون الصفر وال...  info_news       1\n",
      "740   هناك مصادر لقاح أثبتت نجاحها غير أمريكا ويمكن ...  info_news       1\n",
      "963   لو كان اللقاح الأمريكي أمن ومفيد لما أصبحت الو...   personal      -1\n",
      "977   اللقاح الأمريكي لم ينجح في الاختبارات السريرية...  info_news      -1\n",
      "1684    #نريد_لقاح_آمن حتى نأمن صحة اطفالنا في المستقبل   requests       1\n",
      "1878  هناك مصادر لقاح أثبتت نجاحها غير أمريكا ويمكن ...  info_news       1\n",
      "2477  محمد بن زايد: الإمارات قدمت أكثر من مليون و 27...  info_news       1\n",
      "2644         نريد التخلص من كورونا لكننا #نريد_لقاح_آمن   requests       1\n",
      "2646  في ظل تسابق دول العالم على تطعيم شعوبها.. تَعَ...  info_news       1\n",
      "2786  لو كان اللقاح الأمريكي أمن ومفيد لما أصبحت الو...   personal      -1\n",
      "3231  #نريد_لقاح_آمن حتى ترجع الحياة الى طبيعتها بعد...  info_news       1\n",
      "3728    #نريد_لقاح_آمن حتى نأمن صحة اطفالنا في المستقبل   requests       1\n",
      "3801  #نريد_لقاح_آمن حتى ترجع الحياة الى طبيعتها بعد...   requests       1\n",
      "3889         نريد التخلص من كورونا لكننا #نريد_لقاح_آمن  info_news       1\n",
      "3910  امريكا تريد سد عجز أزمتها المالية الخانقة ببيع...  info_news       1\n",
      "4380    #نريد_لقاح_آمن حتى نأمن صحة اطفالنا في المستقبل   requests       1\n",
      "4429        اللقاح الأمريكي غالي ومو آمن #نريد_لقاح_آمن  info_news       1\n",
      "4438  #نريد_لقاح_آمن حتى ترجع الحياة الى طبيعتها بعد...   requests       1\n",
      "4458  اللقاح الأمريكي مفروض على العراق فرضاً<LF>#نري...  info_news       1\n",
      "4473  الذي تفنن بقتلنا لا يؤتمن لكي نأخذ منه اللقاح ...     others       1\n",
      "4576  دعبول حضرتك منو انت وتطلب من قائد دولة إسلامية...  info_news       1\n",
      "4682        اللقاح الأمريكي غالي ومو آمن #نريد_لقاح_آمن  info_news       1\n",
      "4844  #عاجل| #وزير_الصحة_التركي: بدء تطعيم المواطنين...  info_news       1\n",
      "5007  ما سبب الإصرار على اللقاح الأمريكي يوجد إنه في...  info_news      -1\n",
      "5010  تعمد عملاء الداخل يردون فرضه علينا <LF>هذه الف...  info_news       1\n",
      "5033  #نريد_لقاح_آمن حتى ترجع الحياة الى طبيعتها بعد...   personal       1\n",
      "5317  هناك مصادر لقاح أثبتت نجاحها غير أمريكا ويمكن ...  info_news       1\n",
      "5417         نريد التخلص من كورونا لكننا #نريد_لقاح_آمن   personal       1\n",
      "5436  اللقاح الأمريكي لم ينجح في الاختبارات السريرية...  info_news      -1\n",
      "5480  الخائن لا يؤتمن فكيف اذا كانت امريكا هي الخائن...   requests       1\n",
      "5765  روسيا تعلن استعدادها لتزويد مصر بتكنولوجيا تصن...  info_news       1\n",
      "5956  هناك مصادر لقاح أثبتت نجاحها غير أمريكا ويمكن ...  info_news       1\n",
      "5984  هناك مصادر لقاح أثبتت نجاحها غير أمريكا ويمكن ...  info_news       1\n",
      "6029  الذي تفنن بقتلنا لا يؤتمن لكي نأخذ منه اللقاح ...   personal      -1\n",
      "6135             محتاجين لقاح يقاوم الإفراط في التفكير.  unrelated       0\n",
      "6514  #نريد_لقاح_آمن حتى ترجع الحياة الى طبيعتها بعد...   requests       1\n",
      "6858  رئيس لجنة الصحة النيابية النائب عاصم عراجي: طل...       plan       1\n",
      "6899                       نبي لقاح ضد التفكير الزايد .  unrelated       0\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################\")\n",
    "print(\"duplicated rows :\")\n",
    "print(t[t.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t['text']\n",
    "ys = t['stance']\n",
    "yc = t['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    celebrity\n",
      "1    info_news\n",
      "2    info_news\n",
      "3    celebrity\n",
      "4     personal\n",
      "5    info_news\n",
      "6    info_news\n",
      "7     personal\n",
      "8    unrelated\n",
      "9    info_news\n",
      "Name: category, dtype: object\n",
      "[1, 0, 0, 1, 7, 0, 0, 7, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "print(yc[0:10])\n",
    "yc=encode_category(yc)\n",
    "print(yc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev=d['text']\n",
    "ys_dev=d['stance']\n",
    "yc_dev=d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_dev=encode_category(yc_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test data\n",
    "X = X.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dev data\n",
    "X_dev = X_dev.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4298 \n",
      "\n",
      "للأسف حالات #فيروس_كورونا بدأت تتصاعد في السلطنة<LF>ويجب الالتزام بالعادات الصحية حتى نتجنب أي إغلاق قريب في الأنشطة لاسمح الله<LF>#عمان_تواجه_كورونا #عُمان_نهضة_متجددة #فيروس_كورونا #لقاح_كوفيد_19 #عمان_تاريخ_وحضارة #باحثون_عن_عمل_يستغيثون271 #عاطلون_في_بلد_النفط #صباح_الخير #الحمدلله https://t.co/bSrrXe3Otl \n",
      "\n",
      "['أَسَف', 'حالَة', 'بَدَأ', 'تَصاعَد', 'فِي', 'سَلْطَنَة', 'وَجَب', 'ٱِلْتِزام', 'عادَة', 'صِحِّيّ', 'حَتَّى', 'تَجَنَّب', 'أَيّ', 'إِغْلاق', 'قَرِيب', 'فِي', 'نَشاط', 'سَمَح', 'اللَّه', '<LF>', '<LF>', '<NUM>', '<NUM>', '<LINK>', 'فَيْرُوس', 'فَيْرُوس', 'فَيْرُوس', 'كَوَّر', 'كَوَّر', 'كَوَّر', 'عَمّان', 'عَمّان', 'عَمّان', 'واجَه', 'واجَه', 'واجَه', 'كَوَّر', 'كَوَّر', 'كَوَّر', 'عَمّان', 'عَمّان', 'عَمّان', 'نَهْضَة', 'نَهْضَة', 'نَهْضَة', 'مُتَجَدِّد', 'مُتَجَدِّد', 'مُتَجَدِّد', 'فَيْرُوس', 'فَيْرُوس', 'فَيْرُوس', 'كَوَّر', 'كَوَّر', 'كَوَّر', 'لَقاح', 'لَقاح', 'لَقاح', 'كوفيد', 'كوفيد', 'كوفيد', 'عَمّان', 'عَمّان', 'عَمّان', 'تارِيخ', 'تارِيخ', 'تارِيخ', 'حَضارَة', 'حَضارَة', 'حَضارَة', 'باحِث', 'باحِث', 'باحِث', 'عَن', 'عَن', 'عَن', 'عَمَل', 'عَمَل', 'عَمَل', 'ٱِسْتَغاث', 'ٱِسْتَغاث', 'ٱِسْتَغاث', 'عاطِل', 'عاطِل', 'عاطِل', 'فِي', 'فِي', 'فِي', 'بَلَد', 'بَلَد', 'بَلَد', 'نَفْط', 'نَفْط', 'نَفْط', 'صَباح', 'صَباح', 'صَباح', 'خَيْر', 'خَيْر', 'خَيْر', 'الحمدلله', 'الحمدلله', 'الحمدلله'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, len(X))\n",
    "# r = 900\n",
    "print(r, '\\n')\n",
    "print(t.text[r], '\\n')\n",
    "print(X[r], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 \n",
      "\n",
      "تساؤلات آخر ليل <LF>اذا ما كفانا لقاح الكورونا ...بزيدولو مي ؟؟ 😅<LF>#هبل \n",
      "\n",
      "['تَساؤُل', 'آخَر', 'لَيْل', 'إِذا', 'كَفَى', 'لَقاح', 'الكورونا', 'بزيدولو', 'مَيّ', '<', 'smiling', '_', 'face', '_', 'with', '_', 'open', '_', 'mouth', '_', '_', 'cold', '_', 'sweat', '>', '<LF>', '<LF>', 'أَهْبَل', 'أَهْبَل', 'أَهْبَل'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, len(X_dev))\n",
    "r = 150\n",
    "# r = 738\n",
    "print(r, '\\n')\n",
    "print(d.text[r], '\\n')\n",
    "print(X_dev[r], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209605\n",
      "11771\n"
     ]
    }
   ],
   "source": [
    "# Print Vocabulary size\n",
    "lst = [word for x in X for word in x]\n",
    "vocab = set(lst)\n",
    "print(len(lst))\n",
    "print(len(vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train , test and dev features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_bow,test_features_bow=BOW(train_documents=X,test_documents=X_dev)\n",
    "#\n",
    "assert train_features_bow.shape[0] == len(X)\n",
    "assert train_features_bow.shape[1] == len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tfidf,test_features_tfidf=TFIDF(train_documents=X,test_documents=X_dev)\n",
    "#\n",
    "assert train_features_tfidf.shape[0] == len(X)\n",
    "assert train_features_tfidf.shape[1] == len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info_news\n",
      "[('كَوَّر', 261.4992797735222), ('<LF>', 256.44244823851636), ('لَقاح', 208.74808200516057), ('<NUM>', 173.80818903285686), ('<LINK>', 156.12755324107326), ('مِن', 137.00146302072264), ('فِي', 131.46230664440768), ('عاجِل', 99.37734597401408), ('عَلَى', 97.67586237415485), ('صِحَّة', 92.1865397652484), ('فايزر', 79.82700837675176), ('فَيْرُوس', 78.7697622503078), ('جُرْعَة', 75.59346302671747), ('تَطْعِيم', 71.25956737705488), ('عَرَبِيّ', 67.87505718122213), ('أَنَّ', 67.23948489544064), ('أَمْن', 65.6379417933991), ('كوفيد', 64.87517065417268), ('إِلَى', 59.38200948876755), ('أَوَّل', 56.99642908165569)]\n",
      "\n",
      "celebrity\n",
      "[('تَلَقَّى', 108.58172601829166), ('كَوَّر', 106.75747663142474), ('مَلِك', 85.0017931588784), ('خادِم', 81.40516820739016), ('حَرَم', 80.68576686550303), ('<LF>', 80.58930520830215), ('شَرِيف', 75.25967006899324), ('لَقاح', 65.7817740083004), ('<LINK>', 59.74439388913578), ('جُرْعَة', 59.601509573019676), ('أَوَّل', 56.22555863819366), ('مِن', 48.11858498092079), ('بِن', 40.559053724232264), ('سَلْمان', 40.233870010095565), ('كوفيد', 31.609457084603928), ('أَمِير', 29.9433763520548), ('اللَّه', 28.39763933968265), ('سَعُودِيّ', 27.175418223678175), ('عاجِل', 26.587736761681587), ('وَزِير', 24.16905464101238)]\n",
      "\n",
      "plan\n",
      "[('كَوَّر', 51.20427153451625), ('<LF>', 38.92801055517813), ('<NUM>', 33.08347675168071), ('لَقاح', 32.01366197733073), ('<LINK>', 25.519159563746033), ('مِن', 25.44215324157063), ('صِحَّة', 25.406028280315176), ('عاجِل', 21.608978668513814), ('فِي', 21.425951316549956), ('تَطْعِيم', 21.07275579164851), ('مِلْيُون', 17.54417279539951), ('فَيْرُوس', 16.548998461814044), ('عَلَى', 16.264936217180985), ('جُرْعَة', 16.11702853104056), ('أَمارَة', 13.853233089083634), ('وَزِير', 12.948736858361233), ('عَرَبِيّ', 12.47549499888271), ('كوفيد', 11.842983129348047), ('يَوْم', 11.696615125798912), ('ضِدّ', 11.559176698590175)]\n",
      "\n",
      "requests\n",
      "[('أَراد', 21.654859408690886), ('أَمْن', 21.58867199686662), ('لَقاح', 10.002261764163302), ('<LF>', 4.9942252545771675), ('كَوَّر', 4.079248825583848), ('فِي', 3.1940324195054637), ('مِن', 2.9140530176190182), ('عَلَى', 2.911670932555436), ('حَتَّى', 2.8862962747832768), ('أَنَّ', 2.696721951249277), ('إِسْرائِيل', 2.2622786100991394), ('<NUM>', 2.244353309503658), ('<LINK>', 2.146255217220727), ('فِلَسْطِينِيّ', 2.1174260539330314), ('بَعْد', 2.1038058991788104), ('شَيّ', 2.0522555770428172), ('تَطْعِيم', 1.9856969308451817), ('أَوْقَف', 1.9514645568794018), ('طَبِيعَة', 1.9375778488743443), ('حَياة', 1.8932489101945214)]\n",
      "\n",
      "rumors\n",
      "[('<LF>', 6.419654148975123), ('كَوَّر', 6.166744334762872), ('لَقاح', 5.313900177267518), ('أَنَّ', 3.014280263672404), ('<LINK>', 2.6652539421166135), ('صِحَّة', 2.609690512618269), ('<face_with_tears_of_joy>', 2.4969617056834585), ('إِشاعَة', 2.458461551731683), ('مِن', 2.2529010034407246), ('عَلَى', 2.2343619190677), ('عَن', 2.056676423662394), ('فِي', 1.9490675585604194), ('كوفيد', 1.7436587611703356), ('أَمْن', 1.5786901989058142), ('مُتَحَدِّث', 1.568780283350927), ('هٰذا', 1.5589817504257353), ('وِزارَة', 1.5546748523570293), ('هَل', 1.4742859401160011), ('شائِع', 1.4569370829561867), ('<rolling_on_the_floor_laughing>', 1.4531053495653534)]\n",
      "\n",
      "advice\n",
      "[('كَوَّر', 6.227501916530697), ('<LF>', 5.576828305696842), ('لَقاح', 4.306244159925188), ('أَخَذ', 3.5291222603619983), ('<LINK>', 3.519480304979764), ('صِحَّة', 2.443126814050792), ('عَلَى', 2.4176244114505123), ('تَطْعِيم', 2.4038768354954767), ('مِن', 2.3675488596620475), ('كوفيد', 1.985545735813626), ('وَجَب', 1.9803007762428024), ('بُعْد', 1.6413026225935963), ('فِي', 1.6335601672942683), ('<NUM>', 1.609622454865726), ('أَلْقَى', 1.6083542357819174), ('جُرْعَة', 1.5203467681646037), ('خَبِير', 1.2754848127879757), ('هَل', 1.2720594291004153), ('<syringe>', 1.1847746725546138), ('فَيْرُوس', 1.1633134634949296)]\n",
      "\n",
      "restrictions\n",
      "[('سَفَر', 2.2490075207203333), ('<LF>', 1.9076164546570515), ('كَوَّر', 1.742891860241654), ('شَهادَة', 1.4035480333027797), ('جَواز', 1.3633517032451132), ('شَرْط', 1.3031339298285756), ('<NUM>', 1.163396541007083), ('لَقاح', 1.1094078005749501), ('سَماح', 1.063642209072101), ('كوفيد', 1.0037175106808687), ('أَخَذ', 0.9352979661166515), ('بَقِي', 0.8227754180797663), ('هَل', 0.8108804958299095), ('فاوتشي', 0.8009952377918743), ('صِحِّيّ', 0.7920079655654186), ('خارِج', 0.7394624851578027), ('جُرْعَة', 0.7289347531697741), ('صِحَّة', 0.712632259385496), ('<LINK>', 0.6599505626425847), ('سافَر', 0.6257707699902747)]\n",
      "\n",
      "personal\n",
      "[('<LF>', 70.61025071123363), ('لَقاح', 61.49833755244671), ('مِن', 46.44715548741777), ('كَوَّر', 46.256498119419746), ('اللَّه', 41.76938743000526), ('أَمْن', 39.12107780755699), ('أَخَذ', 33.09582280792158), ('عَلَى', 32.91127917693713), ('فِي', 31.335783026964346), ('شُكْر', 31.07694620512462), ('أَراد', 30.33727418157259), ('كوفيد', 29.698984991031157), ('<NUM>', 27.5810938813052), ('<LINK>', 26.520365238529), ('أَنَّ', 26.422895563160274), ('صِحَّة', 25.915660401266365), ('جُرْعَة', 25.57087719215509), ('وَ', 24.403922729447416), ('أَوَّل', 22.806577624085783), ('تَطْعِيم', 21.115435568141677)]\n",
      "\n",
      "unrelated\n",
      "[('<LF>', 20.83862198855951), ('لَقاح', 15.526264626663792), ('أَمْن', 9.83596377512681), ('فِي', 8.756392148226958), ('تَفْكِير', 8.312881811022198), ('<NUM>', 7.186751687280708), ('مِن', 7.004042572055214), ('<LINK>', 6.8726099254060475), ('ضِدّ', 6.60581999456426), ('أَراد', 6.298309066424571), ('أَنَّ', 5.909986503135807), ('لِ', 5.885917458426701), ('نَبِيّ', 5.5919654163174695), ('وَ', 5.271023928274529), ('عَلَى', 5.026768368540059), ('تَطْعِيم', 4.967525856542892), ('<Mt>', 4.9271863660197095), ('كَوَّر', 4.849948387671682), ('زايِد', 4.80052470503397), ('قاوَم', 4.507831011579667)]\n",
      "\n",
      "others\n",
      "[('لَقاح', 10.35442732464352), ('<LF>', 9.86609559321826), ('كَوَّر', 7.542776946148251), ('أَمْن', 6.692969087189043), ('أَراد', 5.652874551970722), ('<face_with_tears_of_joy>', 4.730665866596664), ('<LINK>', 4.70509558820604), ('مِن', 4.397805738287147), ('عَلَى', 4.2181900026829), ('<NUM>', 4.075175895738096), ('فِي', 3.8490094080672432), ('هَل', 3.56449641625049), ('أَنَّ', 3.4376338778993527), ('أَخَذ', 3.4057522853664772), ('_', 3.0766374791140256), ('وَ', 2.931449262886842), ('<Mt>', 2.6372601932164845), ('اللَّه', 2.399104885167479), ('سَعُودِيّ', 2.3952987271215394), ('كوفيد', 2.350534420155215)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer =TfidfVectorizer(analyzer=lambda x: x)\n",
    "train_features= vectorizer.fit_transform(X)\n",
    "# return train_features.toarray(), test_features.toarray()\n",
    "\n",
    "# print 10 words with highest tfidf values for each CATEGORY\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i, category in enumerate(categories):\n",
    "    lst = [0] *len(feature_names)\n",
    "    for row in train_features[np.array(yc) == i].toarray():\n",
    "        lst = [x + y for x, y in zip(lst, row)]\n",
    "    # top 10 words\n",
    "    top20 = np.argsort(lst)[::-1][:20]\n",
    "    # print names and values\n",
    "    print(category)\n",
    "    print([(feature_names[j], lst[j]) for j in top20])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cbow,test_features_cbow=CBOW(train_documents=X,test_documents=X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_sg,test_features_sg=SG(train_documents=X,test_documents=X_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical model Training "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Task Results:\n",
    "\n",
    "|  | SVM | Random Forest | KNN |  Voting system |\n",
    "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
    "| TFIDF |69%  |  |  ||\n",
    "| BOW | 54%  |   |   | |\n",
    "\n",
    "\n",
    "- Stance Task Results:\n",
    "\n",
    "|  | SVM | Random Forest | KNN |  Voting system |\n",
    "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
    "| TFIDF |81%  |  |  ||\n",
    "| BOW | 80%  |   |   | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without sg\n",
    "train_features = np.concatenate((train_features_bow, train_features_tfidf,train_features_cbow), axis=1)\n",
    "test_features = np.concatenate((test_features_bow, test_features_tfidf,test_features_cbow), axis=1)\n",
    "\n",
    "# with sg\n",
    "train_features1 = np.concatenate((train_features_bow, train_features_tfidf,train_features_cbow,train_features_sg), axis=1)\n",
    "test_features1 = np.concatenate((test_features_bow, test_features_tfidf,test_features_cbow,test_features_sg), axis=1)\n",
    "\n",
    "# print(train_features_cbow.shape)\n",
    "# print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       545\n",
      "           1       0.85      0.81      0.83       145\n",
      "           2       0.22      0.16      0.19        82\n",
      "           3       0.33      0.10      0.15        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.50      0.10      0.17        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.47      0.51      0.49       128\n",
      "           8       0.50      0.42      0.45        36\n",
      "           9       0.12      0.06      0.08        17\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.37      0.29      0.31      1000\n",
      "weighted avg       0.61      0.64      0.62      1000\n",
      "\n",
      "========= Stance =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# clss = [NBmodel, KNNmodelو SVMmodel]\n",
    "# clss = [KNNmodel]\n",
    "clss = [LRmodel]\n",
    "#\n",
    "for cls in clss:\n",
    "    #\n",
    "    N = 1000\n",
    "    N = len(train_features)\n",
    "    yc_pred = cls(Xtrain=train_features[:N], y_train=yc[:N], X_test=test_features)\n",
    "    # ys_pred = cls(Xtrain=train_features, y_train=ys, X_test=test_features)\n",
    "    #\n",
    "    print('========= Category =========')\n",
    "    print(metrics.classification_report(y_true=yc_dev,y_pred=yc_pred))\n",
    "    print('========= Stance =========')\n",
    "    # print(metrics.classification_report(y_true=ys_dev,y_pred=ys_pred))\n",
    "\n",
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_pred=SVMmodel(Xtrain=train_features_bow,y_train=yc,X_test=test_features_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pred=SVMmodel(Xtrain=train_features_tfidf,y_train=ys,X_test=test_features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_cbow_pred=SVMmodel(Xtrain=train_features_cbow,y_train=yc,X_test=test_features_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_cbow_pred=SVMmodel(Xtrain=train_features_cbow,y_train=ys,X_test=test_features_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.545\n",
      "The stance accuracy after training on svm on all features :  0.804\n",
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       545\n",
      "           1       0.00      0.00      0.00       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00       128\n",
      "           8       0.00      0.00      0.00        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.05      0.10      0.07      1000\n",
      "weighted avg       0.30      0.55      0.38      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        70\n",
      "           0       0.00      0.00      0.00       126\n",
      "           1       0.80      1.00      0.89       804\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.27      0.33      0.30      1000\n",
      "weighted avg       0.65      0.80      0.72      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_cbow_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_cbow_pred)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy)\n",
    "\n",
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_cbow_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_cbow_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_sg_pred=SVMmodel(Xtrain=train_features_sg,y_train=yc,X_test=test_features_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_sg_pred=SVMmodel(Xtrain=train_features_sg,y_train=ys,X_test=test_features_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.545\n",
      "The stance accuracy after training on svm on all features :  0.804\n",
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       545\n",
      "           1       0.00      0.00      0.00       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00       128\n",
      "           8       0.00      0.00      0.00        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.05      0.10      0.07      1000\n",
      "weighted avg       0.30      0.55      0.38      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        70\n",
      "           0       0.00      0.00      0.00       126\n",
      "           1       0.80      1.00      0.89       804\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.27      0.33      0.30      1000\n",
      "weighted avg       0.65      0.80      0.72      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_sg_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_sg_pred)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy)\n",
    "\n",
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_sg_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_sg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow\n",
    "yc_all_pred=SVMmodel(Xtrain=train_features,y_train=yc,X_test=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow\n",
    "ys_all_pred=SVMmodel(Xtrain=train_features,y_train=ys,X_test=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.648\n",
      "The stance accuracy after training on svm on all features :  0.819\n"
     ]
    }
   ],
   "source": [
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)\n",
    "\n",
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_cbow_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_cbow_pred)\n",
    "\n",
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_all_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_all_pred)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76       545\n",
      "           1       0.90      0.43      0.58       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.69      0.38      0.49       128\n",
      "           8       0.73      0.31      0.43        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.29      0.21      0.23      1000\n",
      "weighted avg       0.58      0.65      0.58      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.09      0.15        70\n",
      "           0       0.53      0.22      0.31       126\n",
      "           1       0.84      0.98      0.90       804\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.68      0.43      0.46      1000\n",
      "weighted avg       0.79      0.82      0.77      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_all_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow, sg\n",
    "yc_all_pred1=SVMmodel(Xtrain=train_features1,y_train=yc,X_test=test_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow, sg\n",
    "ys_all_pred1=SVMmodel(Xtrain=train_features1,y_train=ys,X_test=test_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.63\n",
      "The stance accuracy after training on svm on all features :  0.815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classify_accuracy1=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_all_pred1)\n",
    "stance_accuracy1=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_all_pred1)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy1)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76       545\n",
      "           1       0.90      0.43      0.58       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.69      0.38      0.49       128\n",
      "           8       0.73      0.31      0.43        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.29      0.21      0.23      1000\n",
      "weighted avg       0.58      0.65      0.58      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.09      0.15        70\n",
      "           0       0.53      0.22      0.31       126\n",
      "           1       0.84      0.98      0.90       804\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.68      0.43      0.46      1000\n",
      "weighted avg       0.79      0.82      0.77      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_all_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.09      0.15        70\n",
      "           0       0.53      0.22      0.31       126\n",
      "           1       0.84      0.98      0.90       804\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.68      0.43      0.46      1000\n",
      "weighted avg       0.79      0.82      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_all_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# def initLSTM():\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100 #need to be tuned\n",
    "hidden_size = 50 #need to be tuned\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "n_classes_category = 9\n",
    "n_classes_stance = 3\n",
    "\n",
    "linear_category = nn.Linear(hidden_size, n_classes_category)\n",
    "linear_stance = nn.Linear(hidden_size, n_classes_stance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, sentences):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    final_output = None\n",
    "    ######################### TODO: implement the forward pass ####################################\n",
    "    # (1) Pass the sentences through the embedding layer\n",
    "    # (2) Pass the output of the embedding layer through the LSTM layer\n",
    "    # (3) Pass the output of the LSTM layer through the linear layer\n",
    "    # (4) Apply softmax to the output of the linear layer\n",
    "    # (5) Return the output of the softmax layer\n",
    "    sentences = embedding(sentences)\n",
    "    sentences, _ = lstm(sentences)\n",
    "    sentences_category = linear_category(sentences)\n",
    "    sentences_stance = linear_stance(sentences)\n",
    "    final_output_category = sentences_category\n",
    "    final_output_stance = sentences_stance\n",
    "    ###############################################################################################\n",
    "    return final_output_category, final_output_stance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# MAX_SEQ_LEN = 1000\n",
    "\n",
    "# def model_1():\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim = (len(tokenizer.word_counts) + 1), output_dim = 128, input_length = MAX_SEQ_LEN))\n",
    "#     model.add(LSTM(128))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(3, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# m1 = train(model_1, \n",
    "#            train_text_vec,\n",
    "#            y_train,\n",
    "#            test_text_vec,\n",
    "#            y_test,\n",
    "#            checkpoint_path='model_1.h5',\n",
    "#            class_weights=cws\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3 (tags/v3.10.3:a342a49, Mar 16 2022, 13:07:40) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d93ce000fb5f8fcca2dab3e75c99c50bb371be07ecadf3a0d8d467af599caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
