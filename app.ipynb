{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !camel_data light\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in modules\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics \n",
    "\n",
    "# .py files \n",
    "from preprocess import Preprocess\n",
    "from feature_extraction import BOW\n",
    "from feature_extraction import TFIDF\n",
    "from feature_extraction import CBOW\n",
    "from feature_extraction import SG\n",
    "\n",
    "from classical_models import SVMmodel\n",
    "# Can use this library to reload a specific module if the notebook can't see changes in the imported module\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stance detection labels meaning is as follows:\n",
    "1. Positive (1): means that the tweet author encourages and supports vaccination.\n",
    "2. Negative (-1): means that the tweet author refuses vaccination.\n",
    "3. Neutral (0): means that the tweet neither supports nor refuses vaccination.\n",
    "\n",
    "Category labels meaning is as follows:\n",
    "1. Info_News: Information about vaccination.\n",
    "2. Celebrities: mentioning celebrities taking vaccinations.\n",
    "3. Plan: Governmental plan or progress of vaccination.\n",
    "4. Request: Requests from governments regarding the vaccination process.\n",
    "5. Rumor: the tweet is a rumor.\n",
    "6. Advice: Advice related to the virus or the vaccination\n",
    "7. Restriction: Restrictions due to the virus e.g. traveling.\n",
    "8. Personal: Personal opinion or story about vaccination.\n",
    "9. Unrelated: Unrelated to vaccination.\n",
    "10.Others: Vaccination related but not one of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('./Dataset/train.csv')\n",
    "d = pd.read_csv('./Dataset/dev.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emojis:  True\n",
      "Lemmatizor:  camel\n"
     ]
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "#\n",
    "categories = [\"info_news\", \"celebrity\", \"plan\", \"requests\", \"rumors\", \"advice\", \"restrictions\", \"personal\", \"unrelated\", \"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 9 categories so we have an array of len 9 for each y\n",
    "def encode_category(y):\n",
    "    '''\n",
    "    Input: y a list of string labels for the category of each document \n",
    "    Output: a list of encoded 10 sized array for the category of each doc \n",
    "            for \"other\" category , it has an array =[0 0 0 0 0 0 0 0 0 1] \n",
    "    '''\n",
    "    return [categories.index(ele) for ele in y]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data\n",
    "- 80% tweets are positive (class 1), the rest are neutral and negative.\n",
    "- 50% tweets belongs to info_news category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6988 entries, 0 to 6987\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      6988 non-null   object\n",
      " 1   category  6988 non-null   object\n",
      " 2   stance    6988 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 163.9+ KB\n",
      "None\n",
      "####################################\n",
      "counts for each lablel :\n",
      "info_news       0.517459\n",
      "personal        0.146680\n",
      "celebrity       0.139525\n",
      "plan            0.086720\n",
      "unrelated       0.046222\n",
      "others          0.023898\n",
      "requests        0.016027\n",
      "rumors          0.011305\n",
      "advice          0.009588\n",
      "restrictions    0.002576\n",
      "Name: category, dtype: float64\n",
      "####################################\n",
      "counts for each stance label :\n",
      " 1    0.792501\n",
      " 0    0.144820\n",
      "-1    0.062679\n",
      "Name: stance, dtype: float64\n",
      " 1    0.804\n",
      " 0    0.126\n",
      "-1    0.070\n",
      "Name: stance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# analyze dataset\n",
    "print(t.info())\n",
    "# d\n",
    "# print(d.info())\n",
    "\n",
    "# count for each label\n",
    "print(\"####################################\")\n",
    "print(\"counts for each lablel :\")\n",
    "print(t['category'].value_counts(normalize=True))\n",
    "# same for d\n",
    "# print(d['category'].value_counts(normalize=True))\n",
    "\n",
    "# count for stance labels\n",
    "print(\"####################################\")\n",
    "print(\"counts for each stance label :\")\n",
    "print(t['stance'].value_counts(normalize=True))\n",
    "# d\n",
    "print(d['stance'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t['text']\n",
    "ys = t['stance']\n",
    "yc = t['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "duplicated rows :\n",
      "                                                   text   category  stance\n",
      "529   Ø§Ù„Ù„Ù‚Ø§Ø­ Ù„Ø§Ø²Ù… ÙŠÙ†Ø­ÙØ¸ Ø¨Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ù§Ù  Ø¯ÙˆÙ† Ø§Ù„ØµÙØ± ÙˆØ§Ù„...  info_news       1\n",
      "740   Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "963   Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø£Ù…Ù† ÙˆÙ…ÙÙŠØ¯ Ù„Ù…Ø§ Ø£ØµØ¨Ø­Øª Ø§Ù„Ùˆ...   personal      -1\n",
      "977   Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù„Ù… ÙŠÙ†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ±ÙŠØ©...  info_news      -1\n",
      "1684    #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ Ù†Ø£Ù…Ù† ØµØ­Ø© Ø§Ø·ÙØ§Ù„Ù†Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„   requests       1\n",
      "1878  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "2477  Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø²Ø§ÙŠØ¯: Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ù‚Ø¯Ù…Øª Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„ÙŠÙˆÙ† Ùˆ 27...  info_news       1\n",
      "2644         Ù†Ø±ÙŠØ¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† ÙƒÙˆØ±ÙˆÙ†Ø§ Ù„ÙƒÙ†Ù†Ø§ #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†   requests       1\n",
      "2646  ÙÙŠ Ø¸Ù„ ØªØ³Ø§Ø¨Ù‚ Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù„Ù… Ø¹Ù„Ù‰ ØªØ·Ø¹ÙŠÙ… Ø´Ø¹ÙˆØ¨Ù‡Ø§.. ØªÙØ¹Ù...  info_news       1\n",
      "2786  Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø£Ù…Ù† ÙˆÙ…ÙÙŠØ¯ Ù„Ù…Ø§ Ø£ØµØ¨Ø­Øª Ø§Ù„Ùˆ...   personal      -1\n",
      "3231  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...  info_news       1\n",
      "3728    #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ Ù†Ø£Ù…Ù† ØµØ­Ø© Ø§Ø·ÙØ§Ù„Ù†Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„   requests       1\n",
      "3801  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   requests       1\n",
      "3889         Ù†Ø±ÙŠØ¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† ÙƒÙˆØ±ÙˆÙ†Ø§ Ù„ÙƒÙ†Ù†Ø§ #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†  info_news       1\n",
      "3910  Ø§Ù…Ø±ÙŠÙƒØ§ ØªØ±ÙŠØ¯ Ø³Ø¯ Ø¹Ø¬Ø² Ø£Ø²Ù…ØªÙ‡Ø§ Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø§Ù†Ù‚Ø© Ø¨Ø¨ÙŠØ¹...  info_news       1\n",
      "4380    #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ Ù†Ø£Ù…Ù† ØµØ­Ø© Ø§Ø·ÙØ§Ù„Ù†Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„   requests       1\n",
      "4429        Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ØºØ§Ù„ÙŠ ÙˆÙ…Ùˆ Ø¢Ù…Ù† #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†  info_news       1\n",
      "4438  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   requests       1\n",
      "4458  Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù…ÙØ±ÙˆØ¶ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø§Ù‚ ÙØ±Ø¶Ø§Ù‹<LF>#Ù†Ø±ÙŠ...  info_news       1\n",
      "4473  Ø§Ù„Ø°ÙŠ ØªÙÙ†Ù† Ø¨Ù‚ØªÙ„Ù†Ø§ Ù„Ø§ ÙŠØ¤ØªÙ…Ù† Ù„ÙƒÙŠ Ù†Ø£Ø®Ø° Ù…Ù†Ù‡ Ø§Ù„Ù„Ù‚Ø§Ø­ ...     others       1\n",
      "4576  Ø¯Ø¹Ø¨ÙˆÙ„ Ø­Ø¶Ø±ØªÙƒ Ù…Ù†Ùˆ Ø§Ù†Øª ÙˆØªØ·Ù„Ø¨ Ù…Ù† Ù‚Ø§Ø¦Ø¯ Ø¯ÙˆÙ„Ø© Ø¥Ø³Ù„Ø§Ù…ÙŠØ©...  info_news       1\n",
      "4682        Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ØºØ§Ù„ÙŠ ÙˆÙ…Ùˆ Ø¢Ù…Ù† #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†  info_news       1\n",
      "4844  #Ø¹Ø§Ø¬Ù„| #ÙˆØ²ÙŠØ±_Ø§Ù„ØµØ­Ø©_Ø§Ù„ØªØ±ÙƒÙŠ: Ø¨Ø¯Ø¡ ØªØ·Ø¹ÙŠÙ… Ø§Ù„Ù…ÙˆØ§Ø·Ù†ÙŠÙ†...  info_news       1\n",
      "5007  Ù…Ø§ Ø³Ø¨Ø¨ Ø§Ù„Ø¥ØµØ±Ø§Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ÙŠÙˆØ¬Ø¯ Ø¥Ù†Ù‡ ÙÙŠ...  info_news      -1\n",
      "5010  ØªØ¹Ù…Ø¯ Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø¯Ø§Ø®Ù„ ÙŠØ±Ø¯ÙˆÙ† ÙØ±Ø¶Ù‡ Ø¹Ù„ÙŠÙ†Ø§ <LF>Ù‡Ø°Ù‡ Ø§Ù„Ù...  info_news       1\n",
      "5033  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   personal       1\n",
      "5317  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "5417         Ù†Ø±ÙŠØ¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† ÙƒÙˆØ±ÙˆÙ†Ø§ Ù„ÙƒÙ†Ù†Ø§ #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†   personal       1\n",
      "5436  Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù„Ù… ÙŠÙ†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ±ÙŠØ©...  info_news      -1\n",
      "5480  Ø§Ù„Ø®Ø§Ø¦Ù† Ù„Ø§ ÙŠØ¤ØªÙ…Ù† ÙÙƒÙŠÙ Ø§Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù…Ø±ÙŠÙƒØ§ Ù‡ÙŠ Ø§Ù„Ø®Ø§Ø¦Ù†...   requests       1\n",
      "5765  Ø±ÙˆØ³ÙŠØ§ ØªØ¹Ù„Ù† Ø§Ø³ØªØ¹Ø¯Ø§Ø¯Ù‡Ø§ Ù„ØªØ²ÙˆÙŠØ¯ Ù…ØµØ± Ø¨ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ØªØµÙ†...  info_news       1\n",
      "5956  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "5984  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "6029  Ø§Ù„Ø°ÙŠ ØªÙÙ†Ù† Ø¨Ù‚ØªÙ„Ù†Ø§ Ù„Ø§ ÙŠØ¤ØªÙ…Ù† Ù„ÙƒÙŠ Ù†Ø£Ø®Ø° Ù…Ù†Ù‡ Ø§Ù„Ù„Ù‚Ø§Ø­ ...   personal      -1\n",
      "6135             Ù…Ø­ØªØ§Ø¬ÙŠÙ† Ù„Ù‚Ø§Ø­ ÙŠÙ‚Ø§ÙˆÙ… Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ±.  unrelated       0\n",
      "6514  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   requests       1\n",
      "6858  Ø±Ø¦ÙŠØ³ Ù„Ø¬Ù†Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙŠØ§Ø¨ÙŠØ© Ø§Ù„Ù†Ø§Ø¦Ø¨ Ø¹Ø§ØµÙ… Ø¹Ø±Ø§Ø¬ÙŠ: Ø·Ù„...       plan       1\n",
      "6899                       Ù†Ø¨ÙŠ Ù„Ù‚Ø§Ø­ Ø¶Ø¯ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø²Ø§ÙŠØ¯ .  unrelated       0\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################\")\n",
    "print(\"duplicated rows :\")\n",
    "print(t[t.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t['text']\n",
    "ys = t['stance']\n",
    "yc = t['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    celebrity\n",
      "1    info_news\n",
      "2    info_news\n",
      "3    celebrity\n",
      "4     personal\n",
      "5    info_news\n",
      "6    info_news\n",
      "7     personal\n",
      "8    unrelated\n",
      "9    info_news\n",
      "Name: category, dtype: object\n",
      "[1, 0, 0, 1, 7, 0, 0, 7, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "print(yc[0:10])\n",
    "yc=encode_category(yc)\n",
    "print(yc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev=d['text']\n",
    "ys_dev=d['stance']\n",
    "yc_dev=d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_dev=encode_category(yc_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test data\n",
    "X = X.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dev data\n",
    "X_dev = X_dev.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6916 \n",
      "\n",
      "Ø§Ù„Ø³Ø¯ÙŠØ³ Ø¹Ù† ØªÙ„Ù‚ÙŠ Ø§Ù„Ù…Ù„Ùƒ Ø³Ù„Ù…Ø§Ù† Ù„Ù‚Ø§Ø­ ÙƒÙˆØ±ÙˆÙ†Ø§: Ù‚Ø¯Ù… Ù„Ù„Ø´Ø¹Ø¨ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ ÙˆØ§Ù„Ø¹Ø§Ù„Ù… Ø¯Ø±Ø³Ø§  <LF>https://t.co/wImO0WR13q \n",
      "\n",
      "['Ø§Ù„Ø³Ø¯ÙŠØ³', 'Ø¹ÙÙ†', 'Ø£ÙÙ„Ù’Ù‚ÙÙ‰', 'Ù…ÙÙ„ÙÙƒ', 'Ø³ÙÙ„Ù’Ù…Ø§Ù†', 'Ù„ÙÙ‚Ø§Ø­', 'ÙƒÙÙˆÙ‘ÙØ±', 'Ù‚ÙØ¯Ù‘ÙÙ…', 'Ø´ÙØ¹Ù’Ø¨', 'Ø³ÙØ¹ÙÙˆØ¯ÙÙŠÙ‘', 'Ø¹Ø§Ù„ÙÙ…', 'Ø¯ÙØ±Ù’Ø³', '<LF>', '<LINK>'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, len(X))\n",
    "# r = 900\n",
    "print(r, '\\n')\n",
    "print(t.text[r], '\\n')\n",
    "print(X[r], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 \n",
      "\n",
      "ØªØ³Ø§Ø¤Ù„Ø§Øª Ø¢Ø®Ø± Ù„ÙŠÙ„ <LF>Ø§Ø°Ø§ Ù…Ø§ ÙƒÙØ§Ù†Ø§ Ù„Ù‚Ø§Ø­ Ø§Ù„ÙƒÙˆØ±ÙˆÙ†Ø§ ...Ø¨Ø²ÙŠØ¯ÙˆÙ„Ùˆ Ù…ÙŠ ØŸØŸ ğŸ˜…<LF>#Ù‡Ø¨Ù„ \n",
      "\n",
      "['ØªÙØ³Ø§Ø¤ÙÙ„', 'Ø¢Ø®ÙØ±', 'ÙƒÙÙÙÙ‰', 'Ù„ÙÙ‚Ø§Ø­', 'Ø§Ù„ÙƒÙˆØ±ÙˆÙ†Ø§', 'Ø¨Ø²ÙŠØ¯ÙˆÙ„Ùˆ', 'Ù…ÙÙŠÙ‘', '<LF>', '<smiling_face_with_open_mouth_&_cold_sweat>', '<LF>', 'Ø£ÙÙ‡Ù’Ø¨ÙÙ„', 'Ø£ÙÙ‡Ù’Ø¨ÙÙ„'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, len(X_dev))\n",
    "r = 150\n",
    "# r = 738\n",
    "print(r, '\\n')\n",
    "print(d.text[r], '\\n')\n",
    "print(X_dev[r], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157990\n",
      "11755\n"
     ]
    }
   ],
   "source": [
    "# Print Vocabulary size\n",
    "lst = [word for x in X for word in x]\n",
    "vocab = set(lst)\n",
    "print(len(lst))\n",
    "print(len(vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train , test and dev features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_bow,test_features_bow=BOW(train_documents=X,test_documents=X_dev)\n",
    "#\n",
    "assert train_features_bow.shape[0] == len(X)\n",
    "assert train_features_bow.shape[1] == len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tfidf,test_features_tfidf=TFIDF(train_documents=X,test_documents=X_dev)\n",
    "#\n",
    "assert train_features_tfidf.shape[0] == len(X)\n",
    "assert train_features_tfidf.shape[1] == len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info_news\n",
      "[('<LF>', 294.27850738746736), ('ÙƒÙÙˆÙ‘ÙØ±', 226.6223101860665), ('Ù„ÙÙ‚Ø§Ø­', 216.47097715595743), ('<NUM>', 201.26844710071643), ('<LINK>', 177.23343555817593), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 86.49775703928718), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 83.84257450743797), ('Ø¹Ø§Ø¬ÙÙ„', 82.22749840409844), ('ØµÙØ­Ù‘ÙØ©', 81.42622511965635), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 77.1925725400968), ('ÙØ§ÙŠØ²Ø±', 75.3925624882043), ('ÙƒÙˆÙÙŠØ¯', 60.67509055645215), ('Ù…ÙÙ„Ù’ÙŠÙÙˆÙ†', 58.68444790998813), ('Ø¹ÙØ±ÙØ¨ÙÙŠÙ‘', 56.742524008525024), ('Ø¶ÙØ¯Ù‘', 55.955724898757246), ('Ø¯ÙÙˆÙ’Ù„ÙØ©', 52.39212299688869), ('Ø³ÙØ¹ÙÙˆØ¯ÙÙŠÙ‘', 52.091068021707), ('Ø£ÙÙ…Ø§Ø±ÙØ©', 50.663568829629476), ('ÙŠÙÙˆÙ’Ù…', 48.48224587671623), ('Ø£ÙØ±Ø§Ø¯', 46.33697390658954)]\n",
      "\n",
      "celebrity\n",
      "[('ØªÙÙ„ÙÙ‚Ù‘ÙÙ‰', 116.90073580612544), ('<LF>', 96.44052474656165), ('ÙƒÙÙˆÙ‘ÙØ±', 92.25816784582415), ('Ù…ÙÙ„ÙÙƒ', 80.05493094970217), ('Ø®Ø§Ø¯ÙÙ…', 77.22553708457893), ('Ø­ÙØ±ÙÙ…', 76.63791147518536), ('Ø´ÙØ±ÙÙŠÙ', 70.9978018609423), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 69.98564104042319), ('<LINK>', 69.63818048288577), ('Ù„ÙÙ‚Ø§Ø­', 67.28260845292984), ('Ø³ÙÙ„Ù’Ù…Ø§Ù†', 41.43832195114347), ('Ø§Ù„Ù„Ù‘ÙÙ‡', 35.02221688161321), ('ÙƒÙˆÙÙŠØ¯', 34.75066545738224), ('Ø£ÙÙ…ÙÙŠØ±', 34.48348332805764), ('Ø­ÙÙÙ’Ø¸', 29.76496821377269), ('ÙˆÙØ²ÙÙŠØ±', 25.637885063810263), ('<NUM>', 25.250171341305546), ('Ø³ÙØ¹ÙÙˆØ¯ÙÙŠÙ‘', 25.19018021598461), ('Ø¹ÙØ¨Ù’Ø¯Ø§Ù„Ø¹ÙØ²ÙÙŠØ²', 24.820027105090368), ('Ø¹Ø§Ø¬ÙÙ„', 24.300524636979514)]\n",
      "\n",
      "plan\n",
      "[('<LF>', 44.543281949775725), ('ÙƒÙÙˆÙ‘ÙØ±', 44.16436957329216), ('<NUM>', 38.68463765511055), ('Ù„ÙÙ‚Ø§Ø­', 33.80502591509359), ('<LINK>', 28.885808158086252), ('ØµÙØ­Ù‘ÙØ©', 24.251047930188435), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 23.35797947670318), ('Ù…ÙÙ„Ù’ÙŠÙÙˆÙ†', 19.736029246911855), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 18.809300097735385), ('Ø¹Ø§Ø¬ÙÙ„', 17.936174678968897), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 16.829458390223348), ('Ø£ÙÙ…Ø§Ø±ÙØ©', 13.371749886490681), ('ÙˆÙØ²ÙÙŠØ±', 13.13975937208669), ('ÙŠÙÙˆÙ’Ù…', 12.736569772691869), ('Ø¶ÙØ¯Ù‘', 12.601311637310625), ('Ø£ÙØ¹Ù’Ù„ÙÙ†', 11.496690458184213), ('ÙƒÙˆÙÙŠØ¯', 11.363505643168295), ('Ø£ÙÙ„Ù’Ù', 11.320528802283508), ('Ø¯ÙÙˆÙ’Ù„ÙØ©', 11.232222960438204), ('Ø¹ÙØ±ÙØ¨ÙÙŠÙ‘', 10.578629176518099)]\n",
      "\n",
      "requests\n",
      "[('Ø£ÙØ±Ø§Ø¯', 21.729710367069263), ('Ù„ÙÙ‚Ø§Ø­', 10.137053326428063), ('<LF>', 6.018548326006069), ('ÙƒÙÙˆÙ‘ÙØ±', 3.5074794125918545), ('Ø£ÙÙˆÙ’Ù‚ÙÙ', 2.9513543524320442), ('Ø·ÙØ¨ÙÙŠØ¹ÙØ©', 2.930352384465371), ('Ø´ÙÙŠÙ‘', 2.899453353549001), ('Ø§Ù„ÙØ§ÙŠØ±ÙˆØ³', 2.7490389609248496), ('Ø­ÙÙŠØ§Ø©', 2.7418369299662606), ('Ù…ÙØ³Ù’ØªÙÙ‚Ù’Ø¨ÙÙ„', 2.6915858087533384), ('<NUM>', 2.555971544034251), ('Ø·ÙÙÙ’Ù„', 2.516888676408385), ('<LINK>', 2.436299543966477), ('ØµÙØ­Ù‘ÙØ©', 2.201929729889873), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 2.134720967437606), ('Ø¥ÙØ³Ù’Ø±Ø§Ø¦ÙÙŠÙ„', 2.1337993926346845), ('Ù‚Ø§ØªÙÙ„', 1.859626763111061), ('Ø£ÙÙ…Ù’Ø±ÙÙŠÙƒÙÙŠÙ‘', 1.7955311645767746), ('Ø£ÙÙ…Ù’Ø±ÙÙŠÙƒØ§', 1.7825843792090137), ('ÙÙÙ„ÙØ³Ù’Ø·ÙÙŠÙ†ÙÙŠÙ‘', 1.7154695523186088)]\n",
      "\n",
      "rumors\n",
      "[('<LF>', 7.127487828997555), ('Ù„ÙÙ‚Ø§Ø­', 5.2747087841022715), ('ÙƒÙÙˆÙ‘ÙØ±', 4.790192903606551), ('<LINK>', 3.0022457986942284), ('Ø¥ÙØ´Ø§Ø¹ÙØ©', 2.5714800972452627), ('<face_with_tears_of_joy>', 2.5610453404826203), ('ØµÙØ­Ù‘ÙØ©', 2.505166291795888), ('Ù…ÙØªÙØ­ÙØ¯Ù‘ÙØ«', 1.6103558660511423), ('Ø´Ø§Ø¦ÙØ¹', 1.5949493400429664), ('Ù…ÙØ¤Ø§Ù…ÙØ±ÙØ©', 1.46650097390892), ('<NUM>', 1.466136212085877), ('<rolling_on_the_floor_laughing>', 1.457949266248713), ('ÙˆÙØ²Ø§Ø±ÙØ©', 1.399821804972832), ('<backhand_index_pointing_down>', 1.3758488513367326), ('Ù†ÙØ¸ÙØ±ÙÙŠÙ‘ÙØ©', 1.3498451221736003), ('ÙƒÙˆÙÙŠØ¯', 1.2902872243207608), ('Ø£ÙØ¨Ù’Ø±ÙØ²', 1.268429661199531), ('Ù…ÙØ´Ù‘', 1.2649791135892476), ('Ù…ÙØ¹Ù’Ù„ÙÙˆÙ…ÙØ©', 1.2594233903484404), ('Ø±ÙØ¯Ù‘', 1.2154223365085997)]\n",
      "\n",
      "advice\n",
      "[('<LF>', 6.539433545261279), ('ÙƒÙÙˆÙ‘ÙØ±', 4.883778792794592), ('Ù„ÙÙ‚Ø§Ø­', 4.237927458076373), ('<LINK>', 4.115137130348363), ('ØµÙØ­Ù‘ÙØ©', 2.55980354035126), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 2.453454126585852), ('ÙˆÙØ¬ÙØ¨', 2.202276393689326), ('<NUM>', 1.8935477818201034), ('Ø£ÙÙ„Ù’Ù‚ÙÙ‰', 1.854152191429135), ('ÙƒÙˆÙÙŠØ¯', 1.8485793455088322), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 1.7809755368282238), ('Ø®ÙØ¨ÙÙŠØ±', 1.3531738349385658), ('<syringe>', 1.3232362581766604), ('Ø£ÙÙ…Ù’ÙƒÙÙ†', 1.2948198874326737), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 1.2635761461171375), ('Ø­ÙØµÙÙˆÙ„', 1.226066998210837), ('Ù‚ÙÙŠØ§Ù…', 1.207167019440059), ('Ø¹ÙØ±ÙÙ', 1.1979716296433631), ('ÙŠÙÙˆÙ’Ù…', 1.1969623444170616), ('ØªÙØ·Ù’Ø¨ÙÙŠÙ‚', 1.1941114400229786)]\n",
      "\n",
      "restrictions\n",
      "[('Ø³ÙÙÙØ±', 2.4484145841292215), ('<LF>', 2.2387673663071843), ('<NUM>', 1.4010683973661995), ('Ø´ÙØ±Ù’Ø·', 1.386229062267983), ('Ø¬ÙÙˆØ§Ø²', 1.3220699384245376), ('Ø´ÙÙ‡Ø§Ø¯ÙØ©', 1.2881603451637633), ('ÙƒÙÙˆÙ‘ÙØ±', 1.2489746895787024), ('Ù„ÙÙ‚Ø§Ø­', 1.1098253218190641), ('Ø³ÙÙ…Ø§Ø­', 1.0811041170432563), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 0.8877427741917944), ('ÙƒÙˆÙÙŠØ¯', 0.8681161491646845), ('Ø®Ø§Ø±ÙØ¬', 0.8135259253232314), ('ØµÙØ­Ù‘ÙÙŠÙ‘', 0.8131001601129608), ('ØµÙØ­Ù‘ÙØ©', 0.7885861860251333), ('<LINK>', 0.761689581035269), ('Ø¨ÙÙ‚ÙÙŠ', 0.7415786446419406), ('ÙØ§ÙˆØªØ´ÙŠ', 0.7080342239879253), ('<Mt>', 0.7005269858402317), ('Ø³Ø§ÙÙØ±', 0.6974171588817122), ('Ø­ÙØµÙÙˆÙ„', 0.6742739035458123)]\n",
      "\n",
      "personal\n",
      "[('<LF>', 81.894626253632), ('Ù„ÙÙ‚Ø§Ø­', 63.129432916551735), ('Ø§Ù„Ù„Ù‘ÙÙ‡', 47.20484866433475), ('ÙƒÙÙˆÙ‘ÙØ±', 41.16606841400818), ('Ø´ÙÙƒÙ’Ø±', 34.261708402223356), ('<NUM>', 31.517218966799142), ('<LINK>', 30.698825867079087), ('Ø£ÙØ±Ø§Ø¯', 29.410223311155157), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 28.989888791613264), ('ÙƒÙˆÙÙŠØ¯', 27.367695492914343), ('ØµÙØ­Ù‘ÙØ©', 25.519038682793543), ('Ø­ÙÙ…Ù’Ø¯', 23.156101718570284), ('ÙŠÙÙˆÙ’Ù…', 22.734680263017328), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 21.500491342909896), ('Ø«Ø§Ù†ÙÙŠ', 20.390421273131622), ('Ù…ÙÙˆØ§Ø·ÙÙ†', 17.377362373320267), ('<Mt>', 17.153548323923328), ('ØªÙÙ†Ù’Ø¸ÙÙŠÙ…', 16.39224686343813), ('ÙˆÙØ²Ø§Ø±ÙØ©', 16.001636250082388), ('ØªÙÙ„ÙÙ‚Ù‘ÙÙ‰', 14.86100151291806)]\n",
      "\n",
      "unrelated\n",
      "[('<LF>', 23.658768321799823), ('Ù„ÙÙ‚Ø§Ø­', 15.77531639002766), ('ØªÙÙÙ’ÙƒÙÙŠØ±', 8.353936714595717), ('<NUM>', 8.027219174979809), ('<LINK>', 7.758207358750362), ('Ø¶ÙØ¯Ù‘', 6.965871053549326), ('Ø£ÙØ±Ø§Ø¯', 5.846261977291153), ('Ù†ÙØ¨ÙÙŠÙ‘', 5.787288428183294), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 5.329835631227171), ('<Mt>', 5.170017603347587), ('Ø²Ø§ÙŠÙØ¯', 4.838847414413291), ('Ù‚Ø§ÙˆÙÙ…', 4.540244469483882), ('Ù…ÙØ­Ù’ØªØ§Ø¬', 4.409797370712048), ('ÙƒÙÙˆÙ‘ÙØ±', 4.063979705326059), ('Ù…ÙØ±ÙØ¶', 4.020100315254508), ('Ù±ÙØ­Ù’ØªØ§Ø¬', 3.839211382506741), ('Ù†Ø§Ø³', 3.6631493349990376), ('Ø¥ÙÙÙ’Ø±Ø§Ø·', 3.6115489786326957), ('ï¸', 3.4694972882302006), ('Ù„ÙØ¨Ù’Ù†Ø§Ù†', 3.399952076798069)]\n",
      "\n",
      "others\n",
      "[('<LF>', 11.29315983406956), ('Ù„ÙÙ‚Ø§Ø­', 11.170758626551237), ('ÙƒÙÙˆÙ‘ÙØ±', 7.722342158910509), ('Ø£ÙØ±Ø§Ø¯', 5.692367092503103), ('<LINK>', 5.472044391254545), ('<face_with_tears_of_joy>', 5.047163832461507), ('<NUM>', 4.488849753107799), ('<Mt>', 2.9329726113026466), ('Ø§Ù„Ù„Ù‘ÙÙ‡', 2.6883368201962776), ('Ø³ÙØ¹ÙÙˆØ¯ÙÙŠÙ‘', 2.53692600576294), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 2.4881157487125254), ('Ø¹Ø§Ù„ÙÙ…', 2.17433316782312), ('ÙƒÙˆÙÙŠØ¯', 2.1485349727464635), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 1.7953225159768795), ('Ù„ÙØ¨Ù’Ù†Ø§Ù†ÙÙŠÙ‘', 1.756261603004744), ('Ø¹ÙØ°Ø§Ø¨', 1.7291178743408233), ('ØµÙØ­Ù‘ÙØ©', 1.618949481142853), ('Ø¹ÙÙ…Ù‘', 1.6000896988924111), ('Ø­ÙØ±ÙÙŠØ±ÙÙŠÙ‘', 1.580448216062056), ('Ø¹ÙÙ„ÙÙ…', 1.5069375139017251)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer =TfidfVectorizer(analyzer=lambda x: x)\n",
    "train_features= vectorizer.fit_transform(X)\n",
    "# return train_features.toarray(), test_features.toarray()\n",
    "\n",
    "# print 10 words with highest tfidf values for each CATEGORY\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i, category in enumerate(categories):\n",
    "    lst = [0] *len(feature_names)\n",
    "    for row in train_features[np.array(yc) == i].toarray():\n",
    "        lst = [x + y for x, y in zip(lst, row)]\n",
    "    # top 10 words\n",
    "    top20 = np.argsort(lst)[::-1][:20]\n",
    "    # print names and values\n",
    "    print(category)\n",
    "    print([(feature_names[j], lst[j]) for j in top20])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tfidf,test_features_cbow=CBOW(train_documents=X,test_documents=X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tfidf,test_features_sg=SG(train_documents=X,test_documents=X_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical model Training "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Task Results:\n",
    "\n",
    "|  | SVM | Random Forest | KNN |  Voting system |\n",
    "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
    "| TFIDF |69%  |  |  ||\n",
    "| BOW | 54%  |   |   | |\n",
    "\n",
    "\n",
    "- Stance Task Results:\n",
    "\n",
    "|  | SVM | Random Forest | KNN |  Voting system |\n",
    "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
    "| TFIDF |81%  |  |  ||\n",
    "| BOW | 80%  |   |   | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6988, 11755)\n",
      "(6988, 23510)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.concatenate((train_features_bow, train_features_tfidf), axis=1)\n",
    "test_features = np.concatenate((test_features_bow, test_features_tfidf), axis=1)\n",
    "#\n",
    "print(train_features_bow.shape)\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       545\n",
      "           1       0.85      0.81      0.83       145\n",
      "           2       0.22      0.16      0.19        82\n",
      "           3       0.33      0.10      0.15        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.50      0.10      0.17        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.47      0.51      0.49       128\n",
      "           8       0.50      0.42      0.45        36\n",
      "           9       0.12      0.06      0.08        17\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.37      0.29      0.31      1000\n",
      "weighted avg       0.61      0.64      0.62      1000\n",
      "\n",
      "========= Stance =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# clss = [NBmodel, KNNmodelÙˆ SVMmodel]\n",
    "# clss = [KNNmodel]\n",
    "clss = [LRmodel]\n",
    "#\n",
    "for cls in clss:\n",
    "    #\n",
    "    N = 1000\n",
    "    N = len(train_features)\n",
    "    yc_pred = cls(Xtrain=train_features[:N], y_train=yc[:N], X_test=test_features)\n",
    "    # ys_pred = cls(Xtrain=train_features, y_train=ys, X_test=test_features)\n",
    "    #\n",
    "    print('========= Category =========')\n",
    "    print(metrics.classification_report(y_true=yc_dev,y_pred=yc_pred))\n",
    "    print('========= Stance =========')\n",
    "    # print(metrics.classification_report(y_true=ys_dev,y_pred=ys_pred))\n",
    "\n",
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_pred=SVMmodel(Xtrain=train_features_bow,y_train=yc,X_test=test_features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pred=SVMmodel(Xtrain=train_features_bow,y_train=ys,X_test=test_features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)\n",
    "\n",
    "print(\"The classification accuracy after training on svm on bow features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on bow features : \",stance_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d93ce000fb5f8fcca2dab3e75c99c50bb371be07ecadf3a0d8d467af599caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
