{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt\n",
    "# !camel_data light\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in modules\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics \n",
    "\n",
    "# .py files \n",
    "from preprocess import Preprocess\n",
    "from feature_extraction import BOW\n",
    "from feature_extraction import TFIDF\n",
    "from feature_extraction import CBOW\n",
    "from feature_extraction import SG\n",
    "\n",
    "from classical_models import SVMmodel\n",
    "# Can use this library to reload a specific module if the notebook can't see changes in the imported module\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stance detection labels meaning is as follows:\n",
    "1. Positive (1): means that the tweet author encourages and supports vaccination.\n",
    "2. Negative (-1): means that the tweet author refuses vaccination.\n",
    "3. Neutral (0): means that the tweet neither supports nor refuses vaccination.\n",
    "\n",
    "Category labels meaning is as follows:\n",
    "1. Info_News: Information about vaccination.\n",
    "2. Celebrities: mentioning celebrities taking vaccinations.\n",
    "3. Plan: Governmental plan or progress of vaccination.\n",
    "4. Request: Requests from governments regarding the vaccination process.\n",
    "5. Rumor: the tweet is a rumor.\n",
    "6. Advice: Advice related to the virus or the vaccination\n",
    "7. Restriction: Restrictions due to the virus e.g. traveling.\n",
    "8. Personal: Personal opinion or story about vaccination.\n",
    "9. Unrelated: Unrelated to vaccination.\n",
    "10.Others: Vaccination related but not one of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('./Dataset/train.csv')\n",
    "d = pd.read_csv('./Dataset/dev.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emojis:  True\n",
      "Lemmatizor:  camel\n"
     ]
    }
   ],
   "source": [
    "preprocess = Preprocess()\n",
    "#\n",
    "categories = [\"info_news\", \"celebrity\", \"plan\", \"requests\", \"rumors\", \"advice\", \"restrictions\", \"personal\", \"unrelated\", \"others\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 9 categories so we have an array of len 9 for each y\n",
    "def encode_category(y):\n",
    "    '''\n",
    "    Input: y a list of string labels for the category of each document \n",
    "    Output: a list of encoded 10 sized array for the category of each doc \n",
    "            for \"other\" category , it has an array =[0 0 0 0 0 0 0 0 0 1] \n",
    "    '''\n",
    "    return [categories.index(ele) for ele in y]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data\n",
    "- 80% tweets are positive (class 1), the rest are neutral and negative.\n",
    "- 50% tweets belongs to info_news category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6988 entries, 0 to 6987\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      6988 non-null   object\n",
      " 1   category  6988 non-null   object\n",
      " 2   stance    6988 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 163.9+ KB\n",
      "None\n",
      "####################################\n",
      "counts for each lablel :\n",
      "info_news       0.517459\n",
      "personal        0.146680\n",
      "celebrity       0.139525\n",
      "plan            0.086720\n",
      "unrelated       0.046222\n",
      "others          0.023898\n",
      "requests        0.016027\n",
      "rumors          0.011305\n",
      "advice          0.009588\n",
      "restrictions    0.002576\n",
      "Name: category, dtype: float64\n",
      "####################################\n",
      "counts for each stance label :\n",
      " 1    0.792501\n",
      " 0    0.144820\n",
      "-1    0.062679\n",
      "Name: stance, dtype: float64\n",
      " 1    0.804\n",
      " 0    0.126\n",
      "-1    0.070\n",
      "Name: stance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# analyze dataset\n",
    "print(t.info())\n",
    "# d\n",
    "# print(d.info())\n",
    "\n",
    "# count for each label\n",
    "print(\"####################################\")\n",
    "print(\"counts for each lablel :\")\n",
    "print(t['category'].value_counts(normalize=True))\n",
    "# same for d\n",
    "# print(d['category'].value_counts(normalize=True))\n",
    "\n",
    "# count for stance labels\n",
    "print(\"####################################\")\n",
    "print(\"counts for each stance label :\")\n",
    "print(t['stance'].value_counts(normalize=True))\n",
    "# d\n",
    "print(d['stance'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t['text']\n",
    "ys = t['stance']\n",
    "yc = t['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "duplicated rows :\n",
      "                                                   text   category  stance\n",
      "529   Ø§Ù„Ù„Ù‚Ø§Ø­ Ù„Ø§Ø²Ù… ÙŠÙ†Ø­ÙØ¸ Ø¨Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ù§Ù  Ø¯ÙˆÙ† Ø§Ù„ØµÙØ± ÙˆØ§Ù„...  info_news       1\n",
      "740   Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "963   Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø£Ù…Ù† ÙˆÙ…ÙÙŠØ¯ Ù„Ù…Ø§ Ø£ØµØ¨Ø­Øª Ø§Ù„Ùˆ...   personal      -1\n",
      "977   Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù„Ù… ÙŠÙ†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ±ÙŠØ©...  info_news      -1\n",
      "1684    #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ Ù†Ø£Ù…Ù† ØµØ­Ø© Ø§Ø·ÙØ§Ù„Ù†Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„   requests       1\n",
      "1878  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "2477  Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø²Ø§ÙŠØ¯: Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ù‚Ø¯Ù…Øª Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„ÙŠÙˆÙ† Ùˆ 27...  info_news       1\n",
      "2644         Ù†Ø±ÙŠØ¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† ÙƒÙˆØ±ÙˆÙ†Ø§ Ù„ÙƒÙ†Ù†Ø§ #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†   requests       1\n",
      "2646  ÙÙŠ Ø¸Ù„ ØªØ³Ø§Ø¨Ù‚ Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù„Ù… Ø¹Ù„Ù‰ ØªØ·Ø¹ÙŠÙ… Ø´Ø¹ÙˆØ¨Ù‡Ø§.. ØªÙØ¹Ù...  info_news       1\n",
      "2786  Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø£Ù…Ù† ÙˆÙ…ÙÙŠØ¯ Ù„Ù…Ø§ Ø£ØµØ¨Ø­Øª Ø§Ù„Ùˆ...   personal      -1\n",
      "3231  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...  info_news       1\n",
      "3728    #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ Ù†Ø£Ù…Ù† ØµØ­Ø© Ø§Ø·ÙØ§Ù„Ù†Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„   requests       1\n",
      "3801  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   requests       1\n",
      "3889         Ù†Ø±ÙŠØ¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† ÙƒÙˆØ±ÙˆÙ†Ø§ Ù„ÙƒÙ†Ù†Ø§ #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†  info_news       1\n",
      "3910  Ø§Ù…Ø±ÙŠÙƒØ§ ØªØ±ÙŠØ¯ Ø³Ø¯ Ø¹Ø¬Ø² Ø£Ø²Ù…ØªÙ‡Ø§ Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø§Ù†Ù‚Ø© Ø¨Ø¨ÙŠØ¹...  info_news       1\n",
      "4380    #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ Ù†Ø£Ù…Ù† ØµØ­Ø© Ø§Ø·ÙØ§Ù„Ù†Ø§ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„   requests       1\n",
      "4429        Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ØºØ§Ù„ÙŠ ÙˆÙ…Ùˆ Ø¢Ù…Ù† #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†  info_news       1\n",
      "4438  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   requests       1\n",
      "4458  Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù…ÙØ±ÙˆØ¶ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø§Ù‚ ÙØ±Ø¶Ø§Ù‹<LF>#Ù†Ø±ÙŠ...  info_news       1\n",
      "4473  Ø§Ù„Ø°ÙŠ ØªÙÙ†Ù† Ø¨Ù‚ØªÙ„Ù†Ø§ Ù„Ø§ ÙŠØ¤ØªÙ…Ù† Ù„ÙƒÙŠ Ù†Ø£Ø®Ø° Ù…Ù†Ù‡ Ø§Ù„Ù„Ù‚Ø§Ø­ ...     others       1\n",
      "4576  Ø¯Ø¹Ø¨ÙˆÙ„ Ø­Ø¶Ø±ØªÙƒ Ù…Ù†Ùˆ Ø§Ù†Øª ÙˆØªØ·Ù„Ø¨ Ù…Ù† Ù‚Ø§Ø¦Ø¯ Ø¯ÙˆÙ„Ø© Ø¥Ø³Ù„Ø§Ù…ÙŠØ©...  info_news       1\n",
      "4682        Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ØºØ§Ù„ÙŠ ÙˆÙ…Ùˆ Ø¢Ù…Ù† #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†  info_news       1\n",
      "4844  #Ø¹Ø§Ø¬Ù„| #ÙˆØ²ÙŠØ±_Ø§Ù„ØµØ­Ø©_Ø§Ù„ØªØ±ÙƒÙŠ: Ø¨Ø¯Ø¡ ØªØ·Ø¹ÙŠÙ… Ø§Ù„Ù…ÙˆØ§Ø·Ù†ÙŠÙ†...  info_news       1\n",
      "5007  Ù…Ø§ Ø³Ø¨Ø¨ Ø§Ù„Ø¥ØµØ±Ø§Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ ÙŠÙˆØ¬Ø¯ Ø¥Ù†Ù‡ ÙÙŠ...  info_news      -1\n",
      "5010  ØªØ¹Ù…Ø¯ Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ø¯Ø§Ø®Ù„ ÙŠØ±Ø¯ÙˆÙ† ÙØ±Ø¶Ù‡ Ø¹Ù„ÙŠÙ†Ø§ <LF>Ù‡Ø°Ù‡ Ø§Ù„Ù...  info_news       1\n",
      "5033  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   personal       1\n",
      "5317  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "5417         Ù†Ø±ÙŠØ¯ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† ÙƒÙˆØ±ÙˆÙ†Ø§ Ù„ÙƒÙ†Ù†Ø§ #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù†   personal       1\n",
      "5436  Ø§Ù„Ù„Ù‚Ø§Ø­ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù„Ù… ÙŠÙ†Ø¬Ø­ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ±ÙŠØ©...  info_news      -1\n",
      "5480  Ø§Ù„Ø®Ø§Ø¦Ù† Ù„Ø§ ÙŠØ¤ØªÙ…Ù† ÙÙƒÙŠÙ Ø§Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù…Ø±ÙŠÙƒØ§ Ù‡ÙŠ Ø§Ù„Ø®Ø§Ø¦Ù†...   requests       1\n",
      "5765  Ø±ÙˆØ³ÙŠØ§ ØªØ¹Ù„Ù† Ø§Ø³ØªØ¹Ø¯Ø§Ø¯Ù‡Ø§ Ù„ØªØ²ÙˆÙŠØ¯ Ù…ØµØ± Ø¨ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ ØªØµÙ†...  info_news       1\n",
      "5956  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "5984  Ù‡Ù†Ø§Ùƒ Ù…ØµØ§Ø¯Ø± Ù„Ù‚Ø§Ø­ Ø£Ø«Ø¨ØªØª Ù†Ø¬Ø§Ø­Ù‡Ø§ ØºÙŠØ± Ø£Ù…Ø±ÙŠÙƒØ§ ÙˆÙŠÙ…ÙƒÙ† ...  info_news       1\n",
      "6029  Ø§Ù„Ø°ÙŠ ØªÙÙ†Ù† Ø¨Ù‚ØªÙ„Ù†Ø§ Ù„Ø§ ÙŠØ¤ØªÙ…Ù† Ù„ÙƒÙŠ Ù†Ø£Ø®Ø° Ù…Ù†Ù‡ Ø§Ù„Ù„Ù‚Ø§Ø­ ...   personal      -1\n",
      "6135             Ù…Ø­ØªØ§Ø¬ÙŠÙ† Ù„Ù‚Ø§Ø­ ÙŠÙ‚Ø§ÙˆÙ… Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ±.  unrelated       0\n",
      "6514  #Ù†Ø±ÙŠØ¯_Ù„Ù‚Ø§Ø­_Ø¢Ù…Ù† Ø­ØªÙ‰ ØªØ±Ø¬Ø¹ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù‰ Ø·Ø¨ÙŠØ¹ØªÙ‡Ø§ Ø¨Ø¹Ø¯...   requests       1\n",
      "6858  Ø±Ø¦ÙŠØ³ Ù„Ø¬Ù†Ø© Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙŠØ§Ø¨ÙŠØ© Ø§Ù„Ù†Ø§Ø¦Ø¨ Ø¹Ø§ØµÙ… Ø¹Ø±Ø§Ø¬ÙŠ: Ø·Ù„...       plan       1\n",
      "6899                       Ù†Ø¨ÙŠ Ù„Ù‚Ø§Ø­ Ø¶Ø¯ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø²Ø§ÙŠØ¯ .  unrelated       0\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################\")\n",
    "print(\"duplicated rows :\")\n",
    "print(t[t.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = t['text']\n",
    "ys = t['stance']\n",
    "yc = t['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    celebrity\n",
      "1    info_news\n",
      "2    info_news\n",
      "3    celebrity\n",
      "4     personal\n",
      "5    info_news\n",
      "6    info_news\n",
      "7     personal\n",
      "8    unrelated\n",
      "9    info_news\n",
      "Name: category, dtype: object\n",
      "[1, 0, 0, 1, 7, 0, 0, 7, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "print(yc[0:10])\n",
    "yc=encode_category(yc)\n",
    "print(yc[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev=d['text']\n",
    "ys_dev=d['stance']\n",
    "yc_dev=d['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_dev=encode_category(yc_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the test data\n",
    "X = X.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dev data\n",
    "X_dev = X_dev.apply(preprocess.do_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4298 \n",
      "\n",
      "Ù„Ù„Ø£Ø³Ù Ø­Ø§Ù„Ø§Øª #ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§ Ø¨Ø¯Ø£Øª ØªØªØµØ§Ø¹Ø¯ ÙÙŠ Ø§Ù„Ø³Ù„Ø·Ù†Ø©<LF>ÙˆÙŠØ¬Ø¨ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ø¹Ø§Ø¯Ø§Øª Ø§Ù„ØµØ­ÙŠØ© Ø­ØªÙ‰ Ù†ØªØ¬Ù†Ø¨ Ø£ÙŠ Ø¥ØºÙ„Ø§Ù‚ Ù‚Ø±ÙŠØ¨ ÙÙŠ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ù„Ø§Ø³Ù…Ø­ Ø§Ù„Ù„Ù‡<LF>#Ø¹Ù…Ø§Ù†_ØªÙˆØ§Ø¬Ù‡_ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø¹ÙÙ…Ø§Ù†_Ù†Ù‡Ø¶Ø©_Ù…ØªØ¬Ø¯Ø¯Ø© #ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§ #Ù„Ù‚Ø§Ø­_ÙƒÙˆÙÙŠØ¯_19 #Ø¹Ù…Ø§Ù†_ØªØ§Ø±ÙŠØ®_ÙˆØ­Ø¶Ø§Ø±Ø© #Ø¨Ø§Ø­Ø«ÙˆÙ†_Ø¹Ù†_Ø¹Ù…Ù„_ÙŠØ³ØªØºÙŠØ«ÙˆÙ†271 #Ø¹Ø§Ø·Ù„ÙˆÙ†_ÙÙŠ_Ø¨Ù„Ø¯_Ø§Ù„Ù†ÙØ· #ØµØ¨Ø§Ø­_Ø§Ù„Ø®ÙŠØ± #Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ https://t.co/bSrrXe3Otl \n",
      "\n",
      "['Ø£ÙØ³ÙÙ', 'Ø­Ø§Ù„ÙØ©', 'Ø¨ÙØ¯ÙØ£', 'ØªÙØµØ§Ø¹ÙØ¯', 'ÙÙÙŠ', 'Ø³ÙÙ„Ù’Ø·ÙÙ†ÙØ©', 'ÙˆÙØ¬ÙØ¨', 'Ù±ÙÙ„Ù’ØªÙØ²Ø§Ù…', 'Ø¹Ø§Ø¯ÙØ©', 'ØµÙØ­Ù‘ÙÙŠÙ‘', 'Ø­ÙØªÙ‘ÙÙ‰', 'ØªÙØ¬ÙÙ†Ù‘ÙØ¨', 'Ø£ÙÙŠÙ‘', 'Ø¥ÙØºÙ’Ù„Ø§Ù‚', 'Ù‚ÙØ±ÙÙŠØ¨', 'ÙÙÙŠ', 'Ù†ÙØ´Ø§Ø·', 'Ø³ÙÙ…ÙØ­', 'Ø§Ù„Ù„Ù‘ÙÙ‡', '<LF>', '<LF>', '<NUM>', '<NUM>', '<LINK>', 'ÙÙÙŠÙ’Ø±ÙÙˆØ³', 'ÙÙÙŠÙ’Ø±ÙÙˆØ³', 'ÙÙÙŠÙ’Ø±ÙÙˆØ³', 'ÙƒÙÙˆÙ‘ÙØ±', 'ÙƒÙÙˆÙ‘ÙØ±', 'ÙƒÙÙˆÙ‘ÙØ±', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'ÙˆØ§Ø¬ÙÙ‡', 'ÙˆØ§Ø¬ÙÙ‡', 'ÙˆØ§Ø¬ÙÙ‡', 'ÙƒÙÙˆÙ‘ÙØ±', 'ÙƒÙÙˆÙ‘ÙØ±', 'ÙƒÙÙˆÙ‘ÙØ±', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ù†ÙÙ‡Ù’Ø¶ÙØ©', 'Ù†ÙÙ‡Ù’Ø¶ÙØ©', 'Ù†ÙÙ‡Ù’Ø¶ÙØ©', 'Ù…ÙØªÙØ¬ÙØ¯Ù‘ÙØ¯', 'Ù…ÙØªÙØ¬ÙØ¯Ù‘ÙØ¯', 'Ù…ÙØªÙØ¬ÙØ¯Ù‘ÙØ¯', 'ÙÙÙŠÙ’Ø±ÙÙˆØ³', 'ÙÙÙŠÙ’Ø±ÙÙˆØ³', 'ÙÙÙŠÙ’Ø±ÙÙˆØ³', 'ÙƒÙÙˆÙ‘ÙØ±', 'ÙƒÙÙˆÙ‘ÙØ±', 'ÙƒÙÙˆÙ‘ÙØ±', 'Ù„ÙÙ‚Ø§Ø­', 'Ù„ÙÙ‚Ø§Ø­', 'Ù„ÙÙ‚Ø§Ø­', 'ÙƒÙˆÙÙŠØ¯', 'ÙƒÙˆÙÙŠØ¯', 'ÙƒÙˆÙÙŠØ¯', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'Ø¹ÙÙ…Ù‘Ø§Ù†', 'ØªØ§Ø±ÙÙŠØ®', 'ØªØ§Ø±ÙÙŠØ®', 'ØªØ§Ø±ÙÙŠØ®', 'Ø­ÙØ¶Ø§Ø±ÙØ©', 'Ø­ÙØ¶Ø§Ø±ÙØ©', 'Ø­ÙØ¶Ø§Ø±ÙØ©', 'Ø¨Ø§Ø­ÙØ«', 'Ø¨Ø§Ø­ÙØ«', 'Ø¨Ø§Ø­ÙØ«', 'Ø¹ÙÙ†', 'Ø¹ÙÙ†', 'Ø¹ÙÙ†', 'Ø¹ÙÙ…ÙÙ„', 'Ø¹ÙÙ…ÙÙ„', 'Ø¹ÙÙ…ÙÙ„', 'Ù±ÙØ³Ù’ØªÙØºØ§Ø«', 'Ù±ÙØ³Ù’ØªÙØºØ§Ø«', 'Ù±ÙØ³Ù’ØªÙØºØ§Ø«', 'Ø¹Ø§Ø·ÙÙ„', 'Ø¹Ø§Ø·ÙÙ„', 'Ø¹Ø§Ø·ÙÙ„', 'ÙÙÙŠ', 'ÙÙÙŠ', 'ÙÙÙŠ', 'Ø¨ÙÙ„ÙØ¯', 'Ø¨ÙÙ„ÙØ¯', 'Ø¨ÙÙ„ÙØ¯', 'Ù†ÙÙÙ’Ø·', 'Ù†ÙÙÙ’Ø·', 'Ù†ÙÙÙ’Ø·', 'ØµÙØ¨Ø§Ø­', 'ØµÙØ¨Ø§Ø­', 'ØµÙØ¨Ø§Ø­', 'Ø®ÙÙŠÙ’Ø±', 'Ø®ÙÙŠÙ’Ø±', 'Ø®ÙÙŠÙ’Ø±', 'Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡', 'Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡', 'Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, len(X))\n",
    "# r = 900\n",
    "print(r, '\\n')\n",
    "print(t.text[r], '\\n')\n",
    "print(X[r], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 \n",
      "\n",
      "ØªØ³Ø§Ø¤Ù„Ø§Øª Ø¢Ø®Ø± Ù„ÙŠÙ„ <LF>Ø§Ø°Ø§ Ù…Ø§ ÙƒÙØ§Ù†Ø§ Ù„Ù‚Ø§Ø­ Ø§Ù„ÙƒÙˆØ±ÙˆÙ†Ø§ ...Ø¨Ø²ÙŠØ¯ÙˆÙ„Ùˆ Ù…ÙŠ ØŸØŸ ğŸ˜…<LF>#Ù‡Ø¨Ù„ \n",
      "\n",
      "['ØªÙØ³Ø§Ø¤ÙÙ„', 'Ø¢Ø®ÙØ±', 'Ù„ÙÙŠÙ’Ù„', 'Ø¥ÙØ°Ø§', 'ÙƒÙÙÙÙ‰', 'Ù„ÙÙ‚Ø§Ø­', 'Ø§Ù„ÙƒÙˆØ±ÙˆÙ†Ø§', 'Ø¨Ø²ÙŠØ¯ÙˆÙ„Ùˆ', 'Ù…ÙÙŠÙ‘', '<', 'smiling', '_', 'face', '_', 'with', '_', 'open', '_', 'mouth', '_', '_', 'cold', '_', 'sweat', '>', '<LF>', '<LF>', 'Ø£ÙÙ‡Ù’Ø¨ÙÙ„', 'Ø£ÙÙ‡Ù’Ø¨ÙÙ„', 'Ø£ÙÙ‡Ù’Ø¨ÙÙ„'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = random.randint(0, len(X_dev))\n",
    "r = 150\n",
    "# r = 738\n",
    "print(r, '\\n')\n",
    "print(d.text[r], '\\n')\n",
    "print(X_dev[r], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209605\n",
      "11771\n"
     ]
    }
   ],
   "source": [
    "# Print Vocabulary size\n",
    "lst = [word for x in X for word in x]\n",
    "vocab = set(lst)\n",
    "print(len(lst))\n",
    "print(len(vocab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train , test and dev features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_bow,test_features_bow=BOW(train_documents=X,test_documents=X_dev)\n",
    "#\n",
    "assert train_features_bow.shape[0] == len(X)\n",
    "assert train_features_bow.shape[1] == len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_tfidf,test_features_tfidf=TFIDF(train_documents=X,test_documents=X_dev)\n",
    "#\n",
    "assert train_features_tfidf.shape[0] == len(X)\n",
    "assert train_features_tfidf.shape[1] == len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info_news\n",
      "[('ÙƒÙÙˆÙ‘ÙØ±', 261.4992797735222), ('<LF>', 256.44244823851636), ('Ù„ÙÙ‚Ø§Ø­', 208.74808200516057), ('<NUM>', 173.80818903285686), ('<LINK>', 156.12755324107326), ('Ù…ÙÙ†', 137.00146302072264), ('ÙÙÙŠ', 131.46230664440768), ('Ø¹Ø§Ø¬ÙÙ„', 99.37734597401408), ('Ø¹ÙÙ„ÙÙ‰', 97.67586237415485), ('ØµÙØ­Ù‘ÙØ©', 92.1865397652484), ('ÙØ§ÙŠØ²Ø±', 79.82700837675176), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 78.7697622503078), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 75.59346302671747), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 71.25956737705488), ('Ø¹ÙØ±ÙØ¨ÙÙŠÙ‘', 67.87505718122213), ('Ø£ÙÙ†Ù‘Ù', 67.23948489544064), ('Ø£ÙÙ…Ù’Ù†', 65.6379417933991), ('ÙƒÙˆÙÙŠØ¯', 64.87517065417268), ('Ø¥ÙÙ„ÙÙ‰', 59.38200948876755), ('Ø£ÙÙˆÙ‘ÙÙ„', 56.99642908165569)]\n",
      "\n",
      "celebrity\n",
      "[('ØªÙÙ„ÙÙ‚Ù‘ÙÙ‰', 108.58172601829166), ('ÙƒÙÙˆÙ‘ÙØ±', 106.75747663142474), ('Ù…ÙÙ„ÙÙƒ', 85.0017931588784), ('Ø®Ø§Ø¯ÙÙ…', 81.40516820739016), ('Ø­ÙØ±ÙÙ…', 80.68576686550303), ('<LF>', 80.58930520830215), ('Ø´ÙØ±ÙÙŠÙ', 75.25967006899324), ('Ù„ÙÙ‚Ø§Ø­', 65.7817740083004), ('<LINK>', 59.74439388913578), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 59.601509573019676), ('Ø£ÙÙˆÙ‘ÙÙ„', 56.22555863819366), ('Ù…ÙÙ†', 48.11858498092079), ('Ø¨ÙÙ†', 40.559053724232264), ('Ø³ÙÙ„Ù’Ù…Ø§Ù†', 40.233870010095565), ('ÙƒÙˆÙÙŠØ¯', 31.609457084603928), ('Ø£ÙÙ…ÙÙŠØ±', 29.9433763520548), ('Ø§Ù„Ù„Ù‘ÙÙ‡', 28.39763933968265), ('Ø³ÙØ¹ÙÙˆØ¯ÙÙŠÙ‘', 27.175418223678175), ('Ø¹Ø§Ø¬ÙÙ„', 26.587736761681587), ('ÙˆÙØ²ÙÙŠØ±', 24.16905464101238)]\n",
      "\n",
      "plan\n",
      "[('ÙƒÙÙˆÙ‘ÙØ±', 51.20427153451625), ('<LF>', 38.92801055517813), ('<NUM>', 33.08347675168071), ('Ù„ÙÙ‚Ø§Ø­', 32.01366197733073), ('<LINK>', 25.519159563746033), ('Ù…ÙÙ†', 25.44215324157063), ('ØµÙØ­Ù‘ÙØ©', 25.406028280315176), ('Ø¹Ø§Ø¬ÙÙ„', 21.608978668513814), ('ÙÙÙŠ', 21.425951316549956), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 21.07275579164851), ('Ù…ÙÙ„Ù’ÙŠÙÙˆÙ†', 17.54417279539951), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 16.548998461814044), ('Ø¹ÙÙ„ÙÙ‰', 16.264936217180985), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 16.11702853104056), ('Ø£ÙÙ…Ø§Ø±ÙØ©', 13.853233089083634), ('ÙˆÙØ²ÙÙŠØ±', 12.948736858361233), ('Ø¹ÙØ±ÙØ¨ÙÙŠÙ‘', 12.47549499888271), ('ÙƒÙˆÙÙŠØ¯', 11.842983129348047), ('ÙŠÙÙˆÙ’Ù…', 11.696615125798912), ('Ø¶ÙØ¯Ù‘', 11.559176698590175)]\n",
      "\n",
      "requests\n",
      "[('Ø£ÙØ±Ø§Ø¯', 21.654859408690886), ('Ø£ÙÙ…Ù’Ù†', 21.58867199686662), ('Ù„ÙÙ‚Ø§Ø­', 10.002261764163302), ('<LF>', 4.9942252545771675), ('ÙƒÙÙˆÙ‘ÙØ±', 4.079248825583848), ('ÙÙÙŠ', 3.1940324195054637), ('Ù…ÙÙ†', 2.9140530176190182), ('Ø¹ÙÙ„ÙÙ‰', 2.911670932555436), ('Ø­ÙØªÙ‘ÙÙ‰', 2.8862962747832768), ('Ø£ÙÙ†Ù‘Ù', 2.696721951249277), ('Ø¥ÙØ³Ù’Ø±Ø§Ø¦ÙÙŠÙ„', 2.2622786100991394), ('<NUM>', 2.244353309503658), ('<LINK>', 2.146255217220727), ('ÙÙÙ„ÙØ³Ù’Ø·ÙÙŠÙ†ÙÙŠÙ‘', 2.1174260539330314), ('Ø¨ÙØ¹Ù’Ø¯', 2.1038058991788104), ('Ø´ÙÙŠÙ‘', 2.0522555770428172), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 1.9856969308451817), ('Ø£ÙÙˆÙ’Ù‚ÙÙ', 1.9514645568794018), ('Ø·ÙØ¨ÙÙŠØ¹ÙØ©', 1.9375778488743443), ('Ø­ÙÙŠØ§Ø©', 1.8932489101945214)]\n",
      "\n",
      "rumors\n",
      "[('<LF>', 6.419654148975123), ('ÙƒÙÙˆÙ‘ÙØ±', 6.166744334762872), ('Ù„ÙÙ‚Ø§Ø­', 5.313900177267518), ('Ø£ÙÙ†Ù‘Ù', 3.014280263672404), ('<LINK>', 2.6652539421166135), ('ØµÙØ­Ù‘ÙØ©', 2.609690512618269), ('<face_with_tears_of_joy>', 2.4969617056834585), ('Ø¥ÙØ´Ø§Ø¹ÙØ©', 2.458461551731683), ('Ù…ÙÙ†', 2.2529010034407246), ('Ø¹ÙÙ„ÙÙ‰', 2.2343619190677), ('Ø¹ÙÙ†', 2.056676423662394), ('ÙÙÙŠ', 1.9490675585604194), ('ÙƒÙˆÙÙŠØ¯', 1.7436587611703356), ('Ø£ÙÙ…Ù’Ù†', 1.5786901989058142), ('Ù…ÙØªÙØ­ÙØ¯Ù‘ÙØ«', 1.568780283350927), ('Ù‡Ù°Ø°Ø§', 1.5589817504257353), ('ÙˆÙØ²Ø§Ø±ÙØ©', 1.5546748523570293), ('Ù‡ÙÙ„', 1.4742859401160011), ('Ø´Ø§Ø¦ÙØ¹', 1.4569370829561867), ('<rolling_on_the_floor_laughing>', 1.4531053495653534)]\n",
      "\n",
      "advice\n",
      "[('ÙƒÙÙˆÙ‘ÙØ±', 6.227501916530697), ('<LF>', 5.576828305696842), ('Ù„ÙÙ‚Ø§Ø­', 4.306244159925188), ('Ø£ÙØ®ÙØ°', 3.5291222603619983), ('<LINK>', 3.519480304979764), ('ØµÙØ­Ù‘ÙØ©', 2.443126814050792), ('Ø¹ÙÙ„ÙÙ‰', 2.4176244114505123), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 2.4038768354954767), ('Ù…ÙÙ†', 2.3675488596620475), ('ÙƒÙˆÙÙŠØ¯', 1.985545735813626), ('ÙˆÙØ¬ÙØ¨', 1.9803007762428024), ('Ø¨ÙØ¹Ù’Ø¯', 1.6413026225935963), ('ÙÙÙŠ', 1.6335601672942683), ('<NUM>', 1.609622454865726), ('Ø£ÙÙ„Ù’Ù‚ÙÙ‰', 1.6083542357819174), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 1.5203467681646037), ('Ø®ÙØ¨ÙÙŠØ±', 1.2754848127879757), ('Ù‡ÙÙ„', 1.2720594291004153), ('<syringe>', 1.1847746725546138), ('ÙÙÙŠÙ’Ø±ÙÙˆØ³', 1.1633134634949296)]\n",
      "\n",
      "restrictions\n",
      "[('Ø³ÙÙÙØ±', 2.2490075207203333), ('<LF>', 1.9076164546570515), ('ÙƒÙÙˆÙ‘ÙØ±', 1.742891860241654), ('Ø´ÙÙ‡Ø§Ø¯ÙØ©', 1.4035480333027797), ('Ø¬ÙÙˆØ§Ø²', 1.3633517032451132), ('Ø´ÙØ±Ù’Ø·', 1.3031339298285756), ('<NUM>', 1.163396541007083), ('Ù„ÙÙ‚Ø§Ø­', 1.1094078005749501), ('Ø³ÙÙ…Ø§Ø­', 1.063642209072101), ('ÙƒÙˆÙÙŠØ¯', 1.0037175106808687), ('Ø£ÙØ®ÙØ°', 0.9352979661166515), ('Ø¨ÙÙ‚ÙÙŠ', 0.8227754180797663), ('Ù‡ÙÙ„', 0.8108804958299095), ('ÙØ§ÙˆØªØ´ÙŠ', 0.8009952377918743), ('ØµÙØ­Ù‘ÙÙŠÙ‘', 0.7920079655654186), ('Ø®Ø§Ø±ÙØ¬', 0.7394624851578027), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 0.7289347531697741), ('ØµÙØ­Ù‘ÙØ©', 0.712632259385496), ('<LINK>', 0.6599505626425847), ('Ø³Ø§ÙÙØ±', 0.6257707699902747)]\n",
      "\n",
      "personal\n",
      "[('<LF>', 70.61025071123363), ('Ù„ÙÙ‚Ø§Ø­', 61.49833755244671), ('Ù…ÙÙ†', 46.44715548741777), ('ÙƒÙÙˆÙ‘ÙØ±', 46.256498119419746), ('Ø§Ù„Ù„Ù‘ÙÙ‡', 41.76938743000526), ('Ø£ÙÙ…Ù’Ù†', 39.12107780755699), ('Ø£ÙØ®ÙØ°', 33.09582280792158), ('Ø¹ÙÙ„ÙÙ‰', 32.91127917693713), ('ÙÙÙŠ', 31.335783026964346), ('Ø´ÙÙƒÙ’Ø±', 31.07694620512462), ('Ø£ÙØ±Ø§Ø¯', 30.33727418157259), ('ÙƒÙˆÙÙŠØ¯', 29.698984991031157), ('<NUM>', 27.5810938813052), ('<LINK>', 26.520365238529), ('Ø£ÙÙ†Ù‘Ù', 26.422895563160274), ('ØµÙØ­Ù‘ÙØ©', 25.915660401266365), ('Ø¬ÙØ±Ù’Ø¹ÙØ©', 25.57087719215509), ('ÙˆÙ', 24.403922729447416), ('Ø£ÙÙˆÙ‘ÙÙ„', 22.806577624085783), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 21.115435568141677)]\n",
      "\n",
      "unrelated\n",
      "[('<LF>', 20.83862198855951), ('Ù„ÙÙ‚Ø§Ø­', 15.526264626663792), ('Ø£ÙÙ…Ù’Ù†', 9.83596377512681), ('ÙÙÙŠ', 8.756392148226958), ('ØªÙÙÙ’ÙƒÙÙŠØ±', 8.312881811022198), ('<NUM>', 7.186751687280708), ('Ù…ÙÙ†', 7.004042572055214), ('<LINK>', 6.8726099254060475), ('Ø¶ÙØ¯Ù‘', 6.60581999456426), ('Ø£ÙØ±Ø§Ø¯', 6.298309066424571), ('Ø£ÙÙ†Ù‘Ù', 5.909986503135807), ('Ù„Ù', 5.885917458426701), ('Ù†ÙØ¨ÙÙŠÙ‘', 5.5919654163174695), ('ÙˆÙ', 5.271023928274529), ('Ø¹ÙÙ„ÙÙ‰', 5.026768368540059), ('ØªÙØ·Ù’Ø¹ÙÙŠÙ…', 4.967525856542892), ('<Mt>', 4.9271863660197095), ('ÙƒÙÙˆÙ‘ÙØ±', 4.849948387671682), ('Ø²Ø§ÙŠÙØ¯', 4.80052470503397), ('Ù‚Ø§ÙˆÙÙ…', 4.507831011579667)]\n",
      "\n",
      "others\n",
      "[('Ù„ÙÙ‚Ø§Ø­', 10.35442732464352), ('<LF>', 9.86609559321826), ('ÙƒÙÙˆÙ‘ÙØ±', 7.542776946148251), ('Ø£ÙÙ…Ù’Ù†', 6.692969087189043), ('Ø£ÙØ±Ø§Ø¯', 5.652874551970722), ('<face_with_tears_of_joy>', 4.730665866596664), ('<LINK>', 4.70509558820604), ('Ù…ÙÙ†', 4.397805738287147), ('Ø¹ÙÙ„ÙÙ‰', 4.2181900026829), ('<NUM>', 4.075175895738096), ('ÙÙÙŠ', 3.8490094080672432), ('Ù‡ÙÙ„', 3.56449641625049), ('Ø£ÙÙ†Ù‘Ù', 3.4376338778993527), ('Ø£ÙØ®ÙØ°', 3.4057522853664772), ('_', 3.0766374791140256), ('ÙˆÙ', 2.931449262886842), ('<Mt>', 2.6372601932164845), ('Ø§Ù„Ù„Ù‘ÙÙ‡', 2.399104885167479), ('Ø³ÙØ¹ÙÙˆØ¯ÙÙŠÙ‘', 2.3952987271215394), ('ÙƒÙˆÙÙŠØ¯', 2.350534420155215)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer =TfidfVectorizer(analyzer=lambda x: x)\n",
    "train_features= vectorizer.fit_transform(X)\n",
    "# return train_features.toarray(), test_features.toarray()\n",
    "\n",
    "# print 10 words with highest tfidf values for each CATEGORY\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i, category in enumerate(categories):\n",
    "    lst = [0] *len(feature_names)\n",
    "    for row in train_features[np.array(yc) == i].toarray():\n",
    "        lst = [x + y for x, y in zip(lst, row)]\n",
    "    # top 10 words\n",
    "    top20 = np.argsort(lst)[::-1][:20]\n",
    "    # print names and values\n",
    "    print(category)\n",
    "    print([(feature_names[j], lst[j]) for j in top20])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cbow,test_features_cbow=CBOW(train_documents=X,test_documents=X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_sg,test_features_sg=SG(train_documents=X,test_documents=X_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical model Training "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification Task Results:\n",
    "\n",
    "|  | SVM | Random Forest | KNN |  Voting system |\n",
    "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
    "| TFIDF |69%  |  |  ||\n",
    "| BOW | 54%  |   |   | |\n",
    "\n",
    "\n",
    "- Stance Task Results:\n",
    "\n",
    "|  | SVM | Random Forest | KNN |  Voting system |\n",
    "| --------------- | --------------- | --------------- | --------------- | --------------- |\n",
    "| TFIDF |81%  |  |  ||\n",
    "| BOW | 80%  |   |   | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without sg\n",
    "train_features = np.concatenate((train_features_bow, train_features_tfidf,train_features_cbow), axis=1)\n",
    "test_features = np.concatenate((test_features_bow, test_features_tfidf,test_features_cbow), axis=1)\n",
    "\n",
    "# with sg\n",
    "train_features1 = np.concatenate((train_features_bow, train_features_tfidf,train_features_cbow,train_features_sg), axis=1)\n",
    "test_features1 = np.concatenate((test_features_bow, test_features_tfidf,test_features_cbow,test_features_sg), axis=1)\n",
    "\n",
    "# print(train_features_cbow.shape)\n",
    "# print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73       545\n",
      "           1       0.85      0.81      0.83       145\n",
      "           2       0.22      0.16      0.19        82\n",
      "           3       0.33      0.10      0.15        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.50      0.10      0.17        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.47      0.51      0.49       128\n",
      "           8       0.50      0.42      0.45        36\n",
      "           9       0.12      0.06      0.08        17\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.37      0.29      0.31      1000\n",
      "weighted avg       0.61      0.64      0.62      1000\n",
      "\n",
      "========= Stance =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# clss = [NBmodel, KNNmodelÙˆ SVMmodel]\n",
    "# clss = [KNNmodel]\n",
    "clss = [LRmodel]\n",
    "#\n",
    "for cls in clss:\n",
    "    #\n",
    "    N = 1000\n",
    "    N = len(train_features)\n",
    "    yc_pred = cls(Xtrain=train_features[:N], y_train=yc[:N], X_test=test_features)\n",
    "    # ys_pred = cls(Xtrain=train_features, y_train=ys, X_test=test_features)\n",
    "    #\n",
    "    print('========= Category =========')\n",
    "    print(metrics.classification_report(y_true=yc_dev,y_pred=yc_pred))\n",
    "    print('========= Stance =========')\n",
    "    # print(metrics.classification_report(y_true=ys_dev,y_pred=ys_pred))\n",
    "\n",
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_pred=SVMmodel(Xtrain=train_features_bow,y_train=yc,X_test=test_features_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pred=SVMmodel(Xtrain=train_features_tfidf,y_train=ys,X_test=test_features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_cbow_pred=SVMmodel(Xtrain=train_features_cbow,y_train=yc,X_test=test_features_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_cbow_pred=SVMmodel(Xtrain=train_features_cbow,y_train=ys,X_test=test_features_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.545\n",
      "The stance accuracy after training on svm on all features :  0.804\n",
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       545\n",
      "           1       0.00      0.00      0.00       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00       128\n",
      "           8       0.00      0.00      0.00        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.05      0.10      0.07      1000\n",
      "weighted avg       0.30      0.55      0.38      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        70\n",
      "           0       0.00      0.00      0.00       126\n",
      "           1       0.80      1.00      0.89       804\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.27      0.33      0.30      1000\n",
      "weighted avg       0.65      0.80      0.72      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_cbow_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_cbow_pred)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy)\n",
    "\n",
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_cbow_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_cbow_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_sg_pred=SVMmodel(Xtrain=train_features_sg,y_train=yc,X_test=test_features_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_sg_pred=SVMmodel(Xtrain=train_features_sg,y_train=ys,X_test=test_features_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.545\n",
      "The stance accuracy after training on svm on all features :  0.804\n",
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       545\n",
      "           1       0.00      0.00      0.00       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00       128\n",
      "           8       0.00      0.00      0.00        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.05      0.10      0.07      1000\n",
      "weighted avg       0.30      0.55      0.38      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00        70\n",
      "           0       0.00      0.00      0.00       126\n",
      "           1       0.80      1.00      0.89       804\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.27      0.33      0.30      1000\n",
      "weighted avg       0.65      0.80      0.72      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_sg_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_sg_pred)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy)\n",
    "\n",
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_sg_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_sg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow\n",
    "yc_all_pred=SVMmodel(Xtrain=train_features,y_train=yc,X_test=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow\n",
    "ys_all_pred=SVMmodel(Xtrain=train_features,y_train=ys,X_test=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.648\n",
      "The stance accuracy after training on svm on all features :  0.819\n"
     ]
    }
   ],
   "source": [
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_pred)\n",
    "\n",
    "# classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_cbow_pred)\n",
    "# stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_cbow_pred)\n",
    "\n",
    "classify_accuracy=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_all_pred)\n",
    "stance_accuracy=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_all_pred)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76       545\n",
      "           1       0.90      0.43      0.58       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.69      0.38      0.49       128\n",
      "           8       0.73      0.31      0.43        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.29      0.21      0.23      1000\n",
      "weighted avg       0.58      0.65      0.58      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.09      0.15        70\n",
      "           0       0.53      0.22      0.31       126\n",
      "           1       0.84      0.98      0.90       804\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.68      0.43      0.46      1000\n",
      "weighted avg       0.79      0.82      0.77      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_all_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow, sg\n",
    "yc_all_pred1=SVMmodel(Xtrain=train_features1,y_train=yc,X_test=test_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: bow, tfidf, cbow, sg\n",
    "ys_all_pred1=SVMmodel(Xtrain=train_features1,y_train=ys,X_test=test_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy after training on svm on all features :  0.63\n",
      "The stance accuracy after training on svm on all features :  0.815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classify_accuracy1=metrics.accuracy_score(y_true=yc_dev,y_pred=yc_all_pred1)\n",
    "stance_accuracy1=metrics.accuracy_score(y_true=ys_dev,y_pred=ys_all_pred1)\n",
    "\n",
    "\n",
    "print(\"The classification accuracy after training on svm on all features : \",classify_accuracy1)\n",
    "print(\"The stance accuracy after training on svm on all features : \",stance_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Category =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76       545\n",
      "           1       0.90      0.43      0.58       145\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        15\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.69      0.38      0.49       128\n",
      "           8       0.73      0.31      0.43        36\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.29      0.21      0.23      1000\n",
      "weighted avg       0.58      0.65      0.58      1000\n",
      "\n",
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.09      0.15        70\n",
      "           0       0.53      0.22      0.31       126\n",
      "           1       0.84      0.98      0.90       804\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.68      0.43      0.46      1000\n",
      "weighted avg       0.79      0.82      0.77      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\emada\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_all_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Stance =========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.09      0.15        70\n",
      "           0       0.53      0.22      0.31       126\n",
      "           1       0.84      0.98      0.90       804\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.68      0.43      0.46      1000\n",
      "weighted avg       0.79      0.82      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "print('========= Category =========')\n",
    "print(metrics.classification_report(y_true=yc_dev,y_pred=yc_all_pred))\n",
    "print('========= Stance =========')\n",
    "print(metrics.classification_report(y_true=ys_dev,y_pred=ys_all_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# def initLSTM():\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100 #need to be tuned\n",
    "hidden_size = 50 #need to be tuned\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "n_classes_category = 9\n",
    "n_classes_stance = 3\n",
    "\n",
    "linear_category = nn.Linear(hidden_size, n_classes_category)\n",
    "linear_stance = nn.Linear(hidden_size, n_classes_stance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, sentences):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    final_output = None\n",
    "    ######################### TODO: implement the forward pass ####################################\n",
    "    # (1) Pass the sentences through the embedding layer\n",
    "    # (2) Pass the output of the embedding layer through the LSTM layer\n",
    "    # (3) Pass the output of the LSTM layer through the linear layer\n",
    "    # (4) Apply softmax to the output of the linear layer\n",
    "    # (5) Return the output of the softmax layer\n",
    "    sentences = embedding(sentences)\n",
    "    sentences, _ = lstm(sentences)\n",
    "    sentences_category = linear_category(sentences)\n",
    "    sentences_stance = linear_stance(sentences)\n",
    "    final_output_category = sentences_category\n",
    "    final_output_stance = sentences_stance\n",
    "    ###############################################################################################\n",
    "    return final_output_category, final_output_stance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# MAX_SEQ_LEN = 1000\n",
    "\n",
    "# def model_1():\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim = (len(tokenizer.word_counts) + 1), output_dim = 128, input_length = MAX_SEQ_LEN))\n",
    "#     model.add(LSTM(128))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(3, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# m1 = train(model_1, \n",
    "#            train_text_vec,\n",
    "#            y_train,\n",
    "#            test_text_vec,\n",
    "#            y_test,\n",
    "#            checkpoint_path='model_1.h5',\n",
    "#            class_weights=cws\n",
    "#           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3 (tags/v3.10.3:a342a49, Mar 16 2022, 13:07:40) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d93ce000fb5f8fcca2dab3e75c99c50bb371be07ecadf3a0d8d467af599caa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
